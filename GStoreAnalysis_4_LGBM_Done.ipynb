{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "x_train_reduced = pd.read_csv('x_train_reduced.csv')\n",
    "x_test_reduced = pd.read_csv('x_test_reduced.csv')\n",
    "y_train2 = pd.read_csv('y_train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reduced = x_train_reduced.loc[:, ~x_train_reduced.columns.str.contains('^Unnamed')]\n",
    "x_test_reduced = x_test_reduced.loc[:, ~x_test_reduced.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train3 = y_train2.drop(labels=['fullVisitorId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "# For higher accuracy, tuning max_bin, learning_rate, num_leaves, max_depth, min_data_in_leaf\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_bin': 300, 'max_depth': 15, 'min_data_in_leaf': 50, 'num_leaves': 100}\n",
      "CPU times: user 7d 9h 58min 35s, sys: 3h 49min 13s, total: 7d 13h 47min 49s\n",
      "Wall time: 15h 37min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GBDT\n",
    "estimator = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', bagging_fraction = 0.7,\n",
    "        feature_fraction = 0.7,\n",
    "        bagging_frequency = 6,\n",
    "        bagging_seed = 42,\n",
    "        seed = 42)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0015, 0.0025, 0.005, 0.0075, 0.01],\n",
    "    'num_leaves': [30, 40, 70, 100],\n",
    "    'max_depth': [7, 10, 15, 20],\n",
    "    'max_bin':[255, 300, 350],\n",
    "    'min_data_in_leaf':[20, 50, 100]\n",
    "    }\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=3)\n",
    "gbm.fit(x_train_reduced, y_train3)\n",
    "\n",
    "print(gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drop_rate': 0.05, 'learning_rate': 0.01, 'max_drop': 30, 'num_leaves': 100, 'skip_drop': 0.7}\n",
      "CPU times: user 3d 21min 35s, sys: 1h 17min 33s, total: 3d 1h 39min 8s\n",
      "Wall time: 5h 53min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Dart\n",
    "estimator1 = lgb.LGBMRegressor(boosting_type='dart', objective='regression', \n",
    "                               max_bin=300, min_data_in_leaf=50, max_depth=15,\n",
    "                               bagging_fraction = 0.7, feature_fraction = 0.7, bagging_frequency = 6, \n",
    "                               bagging_seed = 42, seed = 42)\n",
    "\n",
    "param_grid_dart = {\n",
    "    'learning_rate': [0.0025, 0.005, 0.01],\n",
    "    'num_leaves': [40, 70, 100],\n",
    "    'max_drop':[30, 50, 70],\n",
    "    'drop_rate':[0.05, 0.1, 0.2],\n",
    "    'skip_drop':[0.3, 0.5, 0.7]\n",
    "    }\n",
    "\n",
    "gbm_dart = GridSearchCV(estimator1, param_grid_dart, cv=3)\n",
    "gbm_dart.fit(x_train_reduced, y_train3)\n",
    "\n",
    "print(gbm_dart.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dart performance is no better than gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.03, 'num_leaves': 250}\n",
      "CPU times: user 19h 57min 36s, sys: 13min 29s, total: 20h 11min 5s\n",
      "Wall time: 1h 12min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Further increase learning_rate and num_leaves, since other parameters fall in middle of the value interval \n",
    "# GBDT\n",
    "estimator2 = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', bagging_fraction = 0.7,\n",
    "        feature_fraction = 0.7,\n",
    "        bagging_frequency = 6,\n",
    "        bagging_seed = 42,\n",
    "        seed = 42,\n",
    "        max_bin=300,\n",
    "        max_depth=15,\n",
    "        min_data_in_leaf=50)\n",
    "\n",
    "param_grid2 = {\n",
    "    'learning_rate': [0.01, 0.015, 0.02, 0.03],\n",
    "    'num_leaves': [100, 150, 200, 250]\n",
    "    }\n",
    "\n",
    "gbm2 = GridSearchCV(estimator2, param_grid2, cv=3)\n",
    "gbm2.fit(x_train_reduced, y_train3)\n",
    "\n",
    "print(gbm2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'min_data_in_leaf': 50, 'num_leaves': 500}\n",
      "CPU times: user 3d 3h 6min 53s, sys: 1h 2min 5s, total: 3d 4h 8min 59s\n",
      "Wall time: 4h 25min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Continue increase learning_rate and num_leaves \n",
    "# GBDT\n",
    "estimator3 = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', bagging_fraction = 0.7,\n",
    "        feature_fraction = 0.7,\n",
    "        bagging_frequency = 6,\n",
    "        bagging_seed = 42,\n",
    "        seed = 42,\n",
    "        max_bin=300,\n",
    "        max_depth=15)\n",
    "\n",
    "param_grid3 = {\n",
    "    'learning_rate': [0.03, 0.05, 0.1, 0.15],\n",
    "    'num_leaves': [250, 350, 500, 750],\n",
    "    'min_data_in_leaf': [20, 50, 100, 200]\n",
    "    }\n",
    "\n",
    "gbm3 = GridSearchCV(estimator3, param_grid3, cv=3)\n",
    "gbm3.fit(x_train_reduced, y_train3)\n",
    "\n",
    "print(gbm3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 500}\n",
      "CPU times: user 2d 10h 54min 54s, sys: 1h 27min 54s, total: 2d 12h 22min 49s\n",
      "Wall time: 3h 49min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Final fine-tuning\n",
    "estimator4 = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', bagging_fraction = 0.7,\n",
    "        feature_fraction = 0.7,\n",
    "        bagging_frequency = 6,\n",
    "        bagging_seed = 42,\n",
    "        seed = 42,\n",
    "        max_bin=300,\n",
    "        max_depth=15,\n",
    "        min_data_in_leaf=50)\n",
    "\n",
    "param_grid4 = {\n",
    "    'learning_rate': [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'num_leaves': [250, 280, 310, 340, 370, 400, 430, 460, 500, 530]\n",
    "    }\n",
    "\n",
    "gbm4 = GridSearchCV(estimator4, param_grid4, cv=3)\n",
    "gbm4.fit(x_train_reduced, y_train3)\n",
    "\n",
    "print(gbm4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 14.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_round = 7000\n",
    "params = {\"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 500,\n",
    "        \"max_depth\" : 15,\n",
    "        \"boosting\" : \"gbdt\",\n",
    "        \"min_data_in_leaf\": 100,\n",
    "        \"max_bin\": 300,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.74361\tvalid_1's rmse: 1.74545\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's rmse: 1.6246\tvalid_1's rmse: 1.63171\n",
      "[3]\ttraining's rmse: 1.52284\tvalid_1's rmse: 1.5338\n",
      "[4]\ttraining's rmse: 1.42686\tvalid_1's rmse: 1.44259\n",
      "[5]\ttraining's rmse: 1.34216\tvalid_1's rmse: 1.36308\n",
      "[6]\ttraining's rmse: 1.26613\tvalid_1's rmse: 1.29258\n",
      "[7]\ttraining's rmse: 1.19952\tvalid_1's rmse: 1.23182\n",
      "[8]\ttraining's rmse: 1.13944\tvalid_1's rmse: 1.17764\n",
      "[9]\ttraining's rmse: 1.08688\tvalid_1's rmse: 1.13163\n",
      "[10]\ttraining's rmse: 1.03842\tvalid_1's rmse: 1.08837\n",
      "[11]\ttraining's rmse: 0.996421\tvalid_1's rmse: 1.05178\n",
      "[12]\ttraining's rmse: 0.959042\tvalid_1's rmse: 1.02049\n",
      "[13]\ttraining's rmse: 0.92424\tvalid_1's rmse: 0.991022\n",
      "[14]\ttraining's rmse: 0.894705\tvalid_1's rmse: 0.967262\n",
      "[15]\ttraining's rmse: 0.866771\tvalid_1's rmse: 0.945768\n",
      "[16]\ttraining's rmse: 0.841143\tvalid_1's rmse: 0.925859\n",
      "[17]\ttraining's rmse: 0.818196\tvalid_1's rmse: 0.907417\n",
      "[18]\ttraining's rmse: 0.797504\tvalid_1's rmse: 0.892209\n",
      "[19]\ttraining's rmse: 0.777838\tvalid_1's rmse: 0.878656\n",
      "[20]\ttraining's rmse: 0.759371\tvalid_1's rmse: 0.865514\n",
      "[21]\ttraining's rmse: 0.742585\tvalid_1's rmse: 0.853762\n",
      "[22]\ttraining's rmse: 0.727518\tvalid_1's rmse: 0.843506\n",
      "[23]\ttraining's rmse: 0.714033\tvalid_1's rmse: 0.835511\n",
      "[24]\ttraining's rmse: 0.701252\tvalid_1's rmse: 0.827864\n",
      "[25]\ttraining's rmse: 0.68918\tvalid_1's rmse: 0.820173\n",
      "[26]\ttraining's rmse: 0.677827\tvalid_1's rmse: 0.812843\n",
      "[27]\ttraining's rmse: 0.666511\tvalid_1's rmse: 0.805669\n",
      "[28]\ttraining's rmse: 0.656463\tvalid_1's rmse: 0.800358\n",
      "[29]\ttraining's rmse: 0.647276\tvalid_1's rmse: 0.794776\n",
      "[30]\ttraining's rmse: 0.63835\tvalid_1's rmse: 0.789179\n",
      "[31]\ttraining's rmse: 0.630427\tvalid_1's rmse: 0.784711\n",
      "[32]\ttraining's rmse: 0.622281\tvalid_1's rmse: 0.780349\n",
      "[33]\ttraining's rmse: 0.614527\tvalid_1's rmse: 0.7756\n",
      "[34]\ttraining's rmse: 0.607134\tvalid_1's rmse: 0.771404\n",
      "[35]\ttraining's rmse: 0.600179\tvalid_1's rmse: 0.767918\n",
      "[36]\ttraining's rmse: 0.593656\tvalid_1's rmse: 0.765059\n",
      "[37]\ttraining's rmse: 0.586947\tvalid_1's rmse: 0.761629\n",
      "[38]\ttraining's rmse: 0.580982\tvalid_1's rmse: 0.758324\n",
      "[39]\ttraining's rmse: 0.575178\tvalid_1's rmse: 0.756061\n",
      "[40]\ttraining's rmse: 0.569919\tvalid_1's rmse: 0.75277\n",
      "[41]\ttraining's rmse: 0.563889\tvalid_1's rmse: 0.74971\n",
      "[42]\ttraining's rmse: 0.55839\tvalid_1's rmse: 0.747269\n",
      "[43]\ttraining's rmse: 0.553116\tvalid_1's rmse: 0.744716\n",
      "[44]\ttraining's rmse: 0.547815\tvalid_1's rmse: 0.742564\n",
      "[45]\ttraining's rmse: 0.542713\tvalid_1's rmse: 0.740168\n",
      "[46]\ttraining's rmse: 0.538755\tvalid_1's rmse: 0.738217\n",
      "[47]\ttraining's rmse: 0.533808\tvalid_1's rmse: 0.736514\n",
      "[48]\ttraining's rmse: 0.530275\tvalid_1's rmse: 0.735317\n",
      "[49]\ttraining's rmse: 0.525382\tvalid_1's rmse: 0.733382\n",
      "[50]\ttraining's rmse: 0.521146\tvalid_1's rmse: 0.731324\n",
      "[51]\ttraining's rmse: 0.516495\tvalid_1's rmse: 0.729642\n",
      "[52]\ttraining's rmse: 0.513911\tvalid_1's rmse: 0.728696\n",
      "[53]\ttraining's rmse: 0.509838\tvalid_1's rmse: 0.727175\n",
      "[54]\ttraining's rmse: 0.505433\tvalid_1's rmse: 0.725564\n",
      "[55]\ttraining's rmse: 0.501123\tvalid_1's rmse: 0.723252\n",
      "[56]\ttraining's rmse: 0.497641\tvalid_1's rmse: 0.721817\n",
      "[57]\ttraining's rmse: 0.493766\tvalid_1's rmse: 0.720053\n",
      "[58]\ttraining's rmse: 0.489774\tvalid_1's rmse: 0.718744\n",
      "[59]\ttraining's rmse: 0.486259\tvalid_1's rmse: 0.71755\n",
      "[60]\ttraining's rmse: 0.482461\tvalid_1's rmse: 0.715806\n",
      "[61]\ttraining's rmse: 0.479185\tvalid_1's rmse: 0.714442\n",
      "[62]\ttraining's rmse: 0.476604\tvalid_1's rmse: 0.713764\n",
      "[63]\ttraining's rmse: 0.473449\tvalid_1's rmse: 0.71307\n",
      "[64]\ttraining's rmse: 0.470035\tvalid_1's rmse: 0.71199\n",
      "[65]\ttraining's rmse: 0.466532\tvalid_1's rmse: 0.710682\n",
      "[66]\ttraining's rmse: 0.463185\tvalid_1's rmse: 0.709439\n",
      "[67]\ttraining's rmse: 0.460081\tvalid_1's rmse: 0.708319\n",
      "[68]\ttraining's rmse: 0.457378\tvalid_1's rmse: 0.707846\n",
      "[69]\ttraining's rmse: 0.454191\tvalid_1's rmse: 0.706715\n",
      "[70]\ttraining's rmse: 0.450826\tvalid_1's rmse: 0.705415\n",
      "[71]\ttraining's rmse: 0.447978\tvalid_1's rmse: 0.704563\n",
      "[72]\ttraining's rmse: 0.444557\tvalid_1's rmse: 0.703594\n",
      "[73]\ttraining's rmse: 0.441856\tvalid_1's rmse: 0.702753\n",
      "[74]\ttraining's rmse: 0.439017\tvalid_1's rmse: 0.701771\n",
      "[75]\ttraining's rmse: 0.436259\tvalid_1's rmse: 0.70076\n",
      "[76]\ttraining's rmse: 0.433658\tvalid_1's rmse: 0.700022\n",
      "[77]\ttraining's rmse: 0.431686\tvalid_1's rmse: 0.699437\n",
      "[78]\ttraining's rmse: 0.42927\tvalid_1's rmse: 0.698587\n",
      "[79]\ttraining's rmse: 0.426091\tvalid_1's rmse: 0.697431\n",
      "[80]\ttraining's rmse: 0.423685\tvalid_1's rmse: 0.696763\n",
      "[81]\ttraining's rmse: 0.421379\tvalid_1's rmse: 0.695726\n",
      "[82]\ttraining's rmse: 0.419053\tvalid_1's rmse: 0.694662\n",
      "[83]\ttraining's rmse: 0.41726\tvalid_1's rmse: 0.694198\n",
      "[84]\ttraining's rmse: 0.414544\tvalid_1's rmse: 0.693439\n",
      "[85]\ttraining's rmse: 0.412792\tvalid_1's rmse: 0.693016\n",
      "[86]\ttraining's rmse: 0.410187\tvalid_1's rmse: 0.692164\n",
      "[87]\ttraining's rmse: 0.407598\tvalid_1's rmse: 0.691396\n",
      "[88]\ttraining's rmse: 0.404947\tvalid_1's rmse: 0.690351\n",
      "[89]\ttraining's rmse: 0.402546\tvalid_1's rmse: 0.689624\n",
      "[90]\ttraining's rmse: 0.400645\tvalid_1's rmse: 0.689127\n",
      "[91]\ttraining's rmse: 0.398453\tvalid_1's rmse: 0.68845\n",
      "[92]\ttraining's rmse: 0.396229\tvalid_1's rmse: 0.687749\n",
      "[93]\ttraining's rmse: 0.394006\tvalid_1's rmse: 0.687366\n",
      "[94]\ttraining's rmse: 0.391734\tvalid_1's rmse: 0.686498\n",
      "[95]\ttraining's rmse: 0.389131\tvalid_1's rmse: 0.685742\n",
      "[96]\ttraining's rmse: 0.387427\tvalid_1's rmse: 0.685402\n",
      "[97]\ttraining's rmse: 0.385211\tvalid_1's rmse: 0.684972\n",
      "[98]\ttraining's rmse: 0.3824\tvalid_1's rmse: 0.684142\n",
      "[99]\ttraining's rmse: 0.38055\tvalid_1's rmse: 0.683663\n",
      "[100]\ttraining's rmse: 0.378324\tvalid_1's rmse: 0.683013\n",
      "[101]\ttraining's rmse: 0.376216\tvalid_1's rmse: 0.682562\n",
      "[102]\ttraining's rmse: 0.374305\tvalid_1's rmse: 0.682234\n",
      "[103]\ttraining's rmse: 0.372569\tvalid_1's rmse: 0.681619\n",
      "[104]\ttraining's rmse: 0.370015\tvalid_1's rmse: 0.680631\n",
      "[105]\ttraining's rmse: 0.368201\tvalid_1's rmse: 0.680276\n",
      "[106]\ttraining's rmse: 0.366299\tvalid_1's rmse: 0.679648\n",
      "[107]\ttraining's rmse: 0.364121\tvalid_1's rmse: 0.679031\n",
      "[108]\ttraining's rmse: 0.361918\tvalid_1's rmse: 0.678633\n",
      "[109]\ttraining's rmse: 0.360402\tvalid_1's rmse: 0.678402\n",
      "[110]\ttraining's rmse: 0.359176\tvalid_1's rmse: 0.678173\n",
      "[111]\ttraining's rmse: 0.357232\tvalid_1's rmse: 0.677623\n",
      "[112]\ttraining's rmse: 0.355508\tvalid_1's rmse: 0.677452\n",
      "[113]\ttraining's rmse: 0.353602\tvalid_1's rmse: 0.677005\n",
      "[114]\ttraining's rmse: 0.351688\tvalid_1's rmse: 0.67657\n",
      "[115]\ttraining's rmse: 0.350334\tvalid_1's rmse: 0.676173\n",
      "[116]\ttraining's rmse: 0.349204\tvalid_1's rmse: 0.675847\n",
      "[117]\ttraining's rmse: 0.347641\tvalid_1's rmse: 0.675561\n",
      "[118]\ttraining's rmse: 0.345941\tvalid_1's rmse: 0.675121\n",
      "[119]\ttraining's rmse: 0.34425\tvalid_1's rmse: 0.674722\n",
      "[120]\ttraining's rmse: 0.342765\tvalid_1's rmse: 0.674459\n",
      "[121]\ttraining's rmse: 0.341808\tvalid_1's rmse: 0.674315\n",
      "[122]\ttraining's rmse: 0.34001\tvalid_1's rmse: 0.67396\n",
      "[123]\ttraining's rmse: 0.338899\tvalid_1's rmse: 0.673742\n",
      "[124]\ttraining's rmse: 0.337397\tvalid_1's rmse: 0.673505\n",
      "[125]\ttraining's rmse: 0.335709\tvalid_1's rmse: 0.673031\n",
      "[126]\ttraining's rmse: 0.334339\tvalid_1's rmse: 0.672707\n",
      "[127]\ttraining's rmse: 0.332311\tvalid_1's rmse: 0.672201\n",
      "[128]\ttraining's rmse: 0.331501\tvalid_1's rmse: 0.671971\n",
      "[129]\ttraining's rmse: 0.329817\tvalid_1's rmse: 0.671629\n",
      "[130]\ttraining's rmse: 0.328215\tvalid_1's rmse: 0.671173\n",
      "[131]\ttraining's rmse: 0.327151\tvalid_1's rmse: 0.671072\n",
      "[132]\ttraining's rmse: 0.325408\tvalid_1's rmse: 0.670513\n",
      "[133]\ttraining's rmse: 0.324397\tvalid_1's rmse: 0.670283\n",
      "[134]\ttraining's rmse: 0.322884\tvalid_1's rmse: 0.669851\n",
      "[135]\ttraining's rmse: 0.321445\tvalid_1's rmse: 0.669671\n",
      "[136]\ttraining's rmse: 0.319979\tvalid_1's rmse: 0.669645\n",
      "[137]\ttraining's rmse: 0.318439\tvalid_1's rmse: 0.66938\n",
      "[138]\ttraining's rmse: 0.317446\tvalid_1's rmse: 0.669398\n",
      "[139]\ttraining's rmse: 0.316154\tvalid_1's rmse: 0.669179\n",
      "[140]\ttraining's rmse: 0.315226\tvalid_1's rmse: 0.668961\n",
      "[141]\ttraining's rmse: 0.313878\tvalid_1's rmse: 0.668541\n",
      "[142]\ttraining's rmse: 0.312243\tvalid_1's rmse: 0.668079\n",
      "[143]\ttraining's rmse: 0.310734\tvalid_1's rmse: 0.667873\n",
      "[144]\ttraining's rmse: 0.309878\tvalid_1's rmse: 0.667664\n",
      "[145]\ttraining's rmse: 0.308274\tvalid_1's rmse: 0.667254\n",
      "[146]\ttraining's rmse: 0.307281\tvalid_1's rmse: 0.666894\n",
      "[147]\ttraining's rmse: 0.306219\tvalid_1's rmse: 0.666742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148]\ttraining's rmse: 0.305287\tvalid_1's rmse: 0.666592\n",
      "[149]\ttraining's rmse: 0.304216\tvalid_1's rmse: 0.666397\n",
      "[150]\ttraining's rmse: 0.303082\tvalid_1's rmse: 0.666185\n",
      "[151]\ttraining's rmse: 0.302503\tvalid_1's rmse: 0.666079\n",
      "[152]\ttraining's rmse: 0.301262\tvalid_1's rmse: 0.665978\n",
      "[153]\ttraining's rmse: 0.299893\tvalid_1's rmse: 0.665703\n",
      "[154]\ttraining's rmse: 0.298392\tvalid_1's rmse: 0.6654\n",
      "[155]\ttraining's rmse: 0.297384\tvalid_1's rmse: 0.665123\n",
      "[156]\ttraining's rmse: 0.296163\tvalid_1's rmse: 0.664848\n",
      "[157]\ttraining's rmse: 0.294893\tvalid_1's rmse: 0.664701\n",
      "[158]\ttraining's rmse: 0.293443\tvalid_1's rmse: 0.664351\n",
      "[159]\ttraining's rmse: 0.29223\tvalid_1's rmse: 0.66404\n",
      "[160]\ttraining's rmse: 0.291264\tvalid_1's rmse: 0.663998\n",
      "[161]\ttraining's rmse: 0.28965\tvalid_1's rmse: 0.663625\n",
      "[162]\ttraining's rmse: 0.288731\tvalid_1's rmse: 0.66328\n",
      "[163]\ttraining's rmse: 0.287684\tvalid_1's rmse: 0.663091\n",
      "[164]\ttraining's rmse: 0.285989\tvalid_1's rmse: 0.662768\n",
      "[165]\ttraining's rmse: 0.28532\tvalid_1's rmse: 0.662725\n",
      "[166]\ttraining's rmse: 0.284372\tvalid_1's rmse: 0.662558\n",
      "[167]\ttraining's rmse: 0.283049\tvalid_1's rmse: 0.662396\n",
      "[168]\ttraining's rmse: 0.281969\tvalid_1's rmse: 0.66209\n",
      "[169]\ttraining's rmse: 0.281116\tvalid_1's rmse: 0.661885\n",
      "[170]\ttraining's rmse: 0.279854\tvalid_1's rmse: 0.661679\n",
      "[171]\ttraining's rmse: 0.278633\tvalid_1's rmse: 0.66145\n",
      "[172]\ttraining's rmse: 0.277731\tvalid_1's rmse: 0.661135\n",
      "[173]\ttraining's rmse: 0.277062\tvalid_1's rmse: 0.661045\n",
      "[174]\ttraining's rmse: 0.276\tvalid_1's rmse: 0.660749\n",
      "[175]\ttraining's rmse: 0.275496\tvalid_1's rmse: 0.660677\n",
      "[176]\ttraining's rmse: 0.27438\tvalid_1's rmse: 0.660483\n",
      "[177]\ttraining's rmse: 0.273452\tvalid_1's rmse: 0.660283\n",
      "[178]\ttraining's rmse: 0.272221\tvalid_1's rmse: 0.659944\n",
      "[179]\ttraining's rmse: 0.27097\tvalid_1's rmse: 0.659676\n",
      "[180]\ttraining's rmse: 0.2698\tvalid_1's rmse: 0.65961\n",
      "[181]\ttraining's rmse: 0.268819\tvalid_1's rmse: 0.6594\n",
      "[182]\ttraining's rmse: 0.267848\tvalid_1's rmse: 0.659299\n",
      "[183]\ttraining's rmse: 0.266583\tvalid_1's rmse: 0.659028\n",
      "[184]\ttraining's rmse: 0.265411\tvalid_1's rmse: 0.658695\n",
      "[185]\ttraining's rmse: 0.264429\tvalid_1's rmse: 0.65848\n",
      "[186]\ttraining's rmse: 0.263477\tvalid_1's rmse: 0.658296\n",
      "[187]\ttraining's rmse: 0.262512\tvalid_1's rmse: 0.658121\n",
      "[188]\ttraining's rmse: 0.261967\tvalid_1's rmse: 0.658021\n",
      "[189]\ttraining's rmse: 0.261441\tvalid_1's rmse: 0.65785\n",
      "[190]\ttraining's rmse: 0.260318\tvalid_1's rmse: 0.657708\n",
      "[191]\ttraining's rmse: 0.259611\tvalid_1's rmse: 0.657569\n",
      "[192]\ttraining's rmse: 0.258557\tvalid_1's rmse: 0.657257\n",
      "[193]\ttraining's rmse: 0.258116\tvalid_1's rmse: 0.657229\n",
      "[194]\ttraining's rmse: 0.257034\tvalid_1's rmse: 0.657129\n",
      "[195]\ttraining's rmse: 0.255862\tvalid_1's rmse: 0.656861\n",
      "[196]\ttraining's rmse: 0.254725\tvalid_1's rmse: 0.65677\n",
      "[197]\ttraining's rmse: 0.254036\tvalid_1's rmse: 0.656748\n",
      "[198]\ttraining's rmse: 0.253002\tvalid_1's rmse: 0.656429\n",
      "[199]\ttraining's rmse: 0.251907\tvalid_1's rmse: 0.6562\n",
      "[200]\ttraining's rmse: 0.250703\tvalid_1's rmse: 0.655967\n",
      "[201]\ttraining's rmse: 0.249665\tvalid_1's rmse: 0.655805\n",
      "[202]\ttraining's rmse: 0.248532\tvalid_1's rmse: 0.655832\n",
      "[203]\ttraining's rmse: 0.248028\tvalid_1's rmse: 0.655642\n",
      "[204]\ttraining's rmse: 0.246815\tvalid_1's rmse: 0.655416\n",
      "[205]\ttraining's rmse: 0.245954\tvalid_1's rmse: 0.655153\n",
      "[206]\ttraining's rmse: 0.244863\tvalid_1's rmse: 0.654919\n",
      "[207]\ttraining's rmse: 0.244391\tvalid_1's rmse: 0.654816\n",
      "[208]\ttraining's rmse: 0.24358\tvalid_1's rmse: 0.654643\n",
      "[209]\ttraining's rmse: 0.242483\tvalid_1's rmse: 0.654356\n",
      "[210]\ttraining's rmse: 0.241425\tvalid_1's rmse: 0.654211\n",
      "[211]\ttraining's rmse: 0.240606\tvalid_1's rmse: 0.654109\n",
      "[212]\ttraining's rmse: 0.239873\tvalid_1's rmse: 0.653932\n",
      "[213]\ttraining's rmse: 0.238894\tvalid_1's rmse: 0.653855\n",
      "[214]\ttraining's rmse: 0.238433\tvalid_1's rmse: 0.653884\n",
      "[215]\ttraining's rmse: 0.237618\tvalid_1's rmse: 0.653614\n",
      "[216]\ttraining's rmse: 0.237097\tvalid_1's rmse: 0.653495\n",
      "[217]\ttraining's rmse: 0.235833\tvalid_1's rmse: 0.653201\n",
      "[218]\ttraining's rmse: 0.235059\tvalid_1's rmse: 0.653087\n",
      "[219]\ttraining's rmse: 0.234514\tvalid_1's rmse: 0.652984\n",
      "[220]\ttraining's rmse: 0.233767\tvalid_1's rmse: 0.652909\n",
      "[221]\ttraining's rmse: 0.233123\tvalid_1's rmse: 0.652756\n",
      "[222]\ttraining's rmse: 0.232741\tvalid_1's rmse: 0.652613\n",
      "[223]\ttraining's rmse: 0.231711\tvalid_1's rmse: 0.652367\n",
      "[224]\ttraining's rmse: 0.230909\tvalid_1's rmse: 0.652347\n",
      "[225]\ttraining's rmse: 0.230358\tvalid_1's rmse: 0.652246\n",
      "[226]\ttraining's rmse: 0.229656\tvalid_1's rmse: 0.652051\n",
      "[227]\ttraining's rmse: 0.229002\tvalid_1's rmse: 0.651929\n",
      "[228]\ttraining's rmse: 0.228343\tvalid_1's rmse: 0.651898\n",
      "[229]\ttraining's rmse: 0.227768\tvalid_1's rmse: 0.651857\n",
      "[230]\ttraining's rmse: 0.227006\tvalid_1's rmse: 0.651636\n",
      "[231]\ttraining's rmse: 0.226359\tvalid_1's rmse: 0.651562\n",
      "[232]\ttraining's rmse: 0.225392\tvalid_1's rmse: 0.651376\n",
      "[233]\ttraining's rmse: 0.22467\tvalid_1's rmse: 0.651237\n",
      "[234]\ttraining's rmse: 0.223958\tvalid_1's rmse: 0.651081\n",
      "[235]\ttraining's rmse: 0.223318\tvalid_1's rmse: 0.651013\n",
      "[236]\ttraining's rmse: 0.222591\tvalid_1's rmse: 0.650922\n",
      "[237]\ttraining's rmse: 0.221899\tvalid_1's rmse: 0.650814\n",
      "[238]\ttraining's rmse: 0.221462\tvalid_1's rmse: 0.650763\n",
      "[239]\ttraining's rmse: 0.220533\tvalid_1's rmse: 0.650762\n",
      "[240]\ttraining's rmse: 0.219604\tvalid_1's rmse: 0.650576\n",
      "[241]\ttraining's rmse: 0.218637\tvalid_1's rmse: 0.650289\n",
      "[242]\ttraining's rmse: 0.217842\tvalid_1's rmse: 0.65021\n",
      "[243]\ttraining's rmse: 0.217\tvalid_1's rmse: 0.650207\n",
      "[244]\ttraining's rmse: 0.216129\tvalid_1's rmse: 0.650024\n",
      "[245]\ttraining's rmse: 0.215829\tvalid_1's rmse: 0.649989\n",
      "[246]\ttraining's rmse: 0.215247\tvalid_1's rmse: 0.649895\n",
      "[247]\ttraining's rmse: 0.214452\tvalid_1's rmse: 0.649813\n",
      "[248]\ttraining's rmse: 0.21366\tvalid_1's rmse: 0.649737\n",
      "[249]\ttraining's rmse: 0.212979\tvalid_1's rmse: 0.649682\n",
      "[250]\ttraining's rmse: 0.2124\tvalid_1's rmse: 0.64959\n",
      "[251]\ttraining's rmse: 0.211315\tvalid_1's rmse: 0.649322\n",
      "[252]\ttraining's rmse: 0.210617\tvalid_1's rmse: 0.649214\n",
      "[253]\ttraining's rmse: 0.209923\tvalid_1's rmse: 0.649103\n",
      "[254]\ttraining's rmse: 0.209415\tvalid_1's rmse: 0.648969\n",
      "[255]\ttraining's rmse: 0.208615\tvalid_1's rmse: 0.648838\n",
      "[256]\ttraining's rmse: 0.208024\tvalid_1's rmse: 0.648747\n",
      "[257]\ttraining's rmse: 0.20715\tvalid_1's rmse: 0.648647\n",
      "[258]\ttraining's rmse: 0.206566\tvalid_1's rmse: 0.648507\n",
      "[259]\ttraining's rmse: 0.205817\tvalid_1's rmse: 0.648351\n",
      "[260]\ttraining's rmse: 0.205309\tvalid_1's rmse: 0.648285\n",
      "[261]\ttraining's rmse: 0.204793\tvalid_1's rmse: 0.648325\n",
      "[262]\ttraining's rmse: 0.20404\tvalid_1's rmse: 0.648214\n",
      "[263]\ttraining's rmse: 0.203709\tvalid_1's rmse: 0.648117\n",
      "[264]\ttraining's rmse: 0.203388\tvalid_1's rmse: 0.648081\n",
      "[265]\ttraining's rmse: 0.20257\tvalid_1's rmse: 0.647994\n",
      "[266]\ttraining's rmse: 0.202091\tvalid_1's rmse: 0.647947\n",
      "[267]\ttraining's rmse: 0.201481\tvalid_1's rmse: 0.647749\n",
      "[268]\ttraining's rmse: 0.200889\tvalid_1's rmse: 0.647546\n",
      "[269]\ttraining's rmse: 0.200217\tvalid_1's rmse: 0.647425\n",
      "[270]\ttraining's rmse: 0.199754\tvalid_1's rmse: 0.647365\n",
      "[271]\ttraining's rmse: 0.199249\tvalid_1's rmse: 0.64727\n",
      "[272]\ttraining's rmse: 0.198615\tvalid_1's rmse: 0.647114\n",
      "[273]\ttraining's rmse: 0.198007\tvalid_1's rmse: 0.647049\n",
      "[274]\ttraining's rmse: 0.197327\tvalid_1's rmse: 0.646875\n",
      "[275]\ttraining's rmse: 0.196629\tvalid_1's rmse: 0.646824\n",
      "[276]\ttraining's rmse: 0.195909\tvalid_1's rmse: 0.646704\n",
      "[277]\ttraining's rmse: 0.195158\tvalid_1's rmse: 0.646641\n",
      "[278]\ttraining's rmse: 0.194407\tvalid_1's rmse: 0.64662\n",
      "[279]\ttraining's rmse: 0.193927\tvalid_1's rmse: 0.646512\n",
      "[280]\ttraining's rmse: 0.193268\tvalid_1's rmse: 0.646497\n",
      "[281]\ttraining's rmse: 0.192419\tvalid_1's rmse: 0.646378\n",
      "[282]\ttraining's rmse: 0.191722\tvalid_1's rmse: 0.646239\n",
      "[283]\ttraining's rmse: 0.19109\tvalid_1's rmse: 0.646052\n",
      "[284]\ttraining's rmse: 0.190434\tvalid_1's rmse: 0.645856\n",
      "[285]\ttraining's rmse: 0.190067\tvalid_1's rmse: 0.645768\n",
      "[286]\ttraining's rmse: 0.189404\tvalid_1's rmse: 0.64563\n",
      "[287]\ttraining's rmse: 0.188916\tvalid_1's rmse: 0.645661\n",
      "[288]\ttraining's rmse: 0.188476\tvalid_1's rmse: 0.645627\n",
      "[289]\ttraining's rmse: 0.187869\tvalid_1's rmse: 0.645527\n",
      "[290]\ttraining's rmse: 0.187461\tvalid_1's rmse: 0.645528\n",
      "[291]\ttraining's rmse: 0.187062\tvalid_1's rmse: 0.645484\n",
      "[292]\ttraining's rmse: 0.18657\tvalid_1's rmse: 0.645413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293]\ttraining's rmse: 0.185975\tvalid_1's rmse: 0.645429\n",
      "[294]\ttraining's rmse: 0.185308\tvalid_1's rmse: 0.645335\n",
      "[295]\ttraining's rmse: 0.185127\tvalid_1's rmse: 0.645311\n",
      "[296]\ttraining's rmse: 0.184681\tvalid_1's rmse: 0.645142\n",
      "[297]\ttraining's rmse: 0.184323\tvalid_1's rmse: 0.645071\n",
      "[298]\ttraining's rmse: 0.183495\tvalid_1's rmse: 0.644954\n",
      "[299]\ttraining's rmse: 0.183145\tvalid_1's rmse: 0.644873\n",
      "[300]\ttraining's rmse: 0.182786\tvalid_1's rmse: 0.644792\n",
      "[301]\ttraining's rmse: 0.182191\tvalid_1's rmse: 0.644682\n",
      "[302]\ttraining's rmse: 0.181558\tvalid_1's rmse: 0.644591\n",
      "[303]\ttraining's rmse: 0.181238\tvalid_1's rmse: 0.644522\n",
      "[304]\ttraining's rmse: 0.180585\tvalid_1's rmse: 0.644486\n",
      "[305]\ttraining's rmse: 0.180183\tvalid_1's rmse: 0.644411\n",
      "[306]\ttraining's rmse: 0.179891\tvalid_1's rmse: 0.644428\n",
      "[307]\ttraining's rmse: 0.179346\tvalid_1's rmse: 0.644438\n",
      "[308]\ttraining's rmse: 0.178788\tvalid_1's rmse: 0.644317\n",
      "[309]\ttraining's rmse: 0.178434\tvalid_1's rmse: 0.644213\n",
      "[310]\ttraining's rmse: 0.177858\tvalid_1's rmse: 0.644062\n",
      "[311]\ttraining's rmse: 0.177155\tvalid_1's rmse: 0.643875\n",
      "[312]\ttraining's rmse: 0.176917\tvalid_1's rmse: 0.643792\n",
      "[313]\ttraining's rmse: 0.176572\tvalid_1's rmse: 0.643767\n",
      "[314]\ttraining's rmse: 0.176041\tvalid_1's rmse: 0.643706\n",
      "[315]\ttraining's rmse: 0.175402\tvalid_1's rmse: 0.643576\n",
      "[316]\ttraining's rmse: 0.175115\tvalid_1's rmse: 0.643534\n",
      "[317]\ttraining's rmse: 0.17459\tvalid_1's rmse: 0.643498\n",
      "[318]\ttraining's rmse: 0.174033\tvalid_1's rmse: 0.643452\n",
      "[319]\ttraining's rmse: 0.173357\tvalid_1's rmse: 0.643422\n",
      "[320]\ttraining's rmse: 0.172771\tvalid_1's rmse: 0.643294\n",
      "[321]\ttraining's rmse: 0.172435\tvalid_1's rmse: 0.643217\n",
      "[322]\ttraining's rmse: 0.171908\tvalid_1's rmse: 0.643235\n",
      "[323]\ttraining's rmse: 0.171543\tvalid_1's rmse: 0.643182\n",
      "[324]\ttraining's rmse: 0.17103\tvalid_1's rmse: 0.643132\n",
      "[325]\ttraining's rmse: 0.170651\tvalid_1's rmse: 0.64312\n",
      "[326]\ttraining's rmse: 0.169879\tvalid_1's rmse: 0.642995\n",
      "[327]\ttraining's rmse: 0.169498\tvalid_1's rmse: 0.64296\n",
      "[328]\ttraining's rmse: 0.169197\tvalid_1's rmse: 0.642896\n",
      "[329]\ttraining's rmse: 0.168807\tvalid_1's rmse: 0.642867\n",
      "[330]\ttraining's rmse: 0.168502\tvalid_1's rmse: 0.642835\n",
      "[331]\ttraining's rmse: 0.168099\tvalid_1's rmse: 0.64276\n",
      "[332]\ttraining's rmse: 0.167686\tvalid_1's rmse: 0.642712\n",
      "[333]\ttraining's rmse: 0.167272\tvalid_1's rmse: 0.642632\n",
      "[334]\ttraining's rmse: 0.166897\tvalid_1's rmse: 0.642557\n",
      "[335]\ttraining's rmse: 0.166431\tvalid_1's rmse: 0.642469\n",
      "[336]\ttraining's rmse: 0.165822\tvalid_1's rmse: 0.642307\n",
      "[337]\ttraining's rmse: 0.165246\tvalid_1's rmse: 0.642323\n",
      "[338]\ttraining's rmse: 0.164457\tvalid_1's rmse: 0.642209\n",
      "[339]\ttraining's rmse: 0.163852\tvalid_1's rmse: 0.642205\n",
      "[340]\ttraining's rmse: 0.163447\tvalid_1's rmse: 0.64218\n",
      "[341]\ttraining's rmse: 0.162741\tvalid_1's rmse: 0.642041\n",
      "[342]\ttraining's rmse: 0.162209\tvalid_1's rmse: 0.641928\n",
      "[343]\ttraining's rmse: 0.161872\tvalid_1's rmse: 0.641934\n",
      "[344]\ttraining's rmse: 0.161341\tvalid_1's rmse: 0.64184\n",
      "[345]\ttraining's rmse: 0.160894\tvalid_1's rmse: 0.641753\n",
      "[346]\ttraining's rmse: 0.1606\tvalid_1's rmse: 0.641668\n",
      "[347]\ttraining's rmse: 0.15998\tvalid_1's rmse: 0.641557\n",
      "[348]\ttraining's rmse: 0.159559\tvalid_1's rmse: 0.641566\n",
      "[349]\ttraining's rmse: 0.159175\tvalid_1's rmse: 0.641482\n",
      "[350]\ttraining's rmse: 0.158888\tvalid_1's rmse: 0.641462\n",
      "[351]\ttraining's rmse: 0.158461\tvalid_1's rmse: 0.64138\n",
      "[352]\ttraining's rmse: 0.15815\tvalid_1's rmse: 0.641303\n",
      "[353]\ttraining's rmse: 0.157575\tvalid_1's rmse: 0.641257\n",
      "[354]\ttraining's rmse: 0.157414\tvalid_1's rmse: 0.641206\n",
      "[355]\ttraining's rmse: 0.156833\tvalid_1's rmse: 0.641121\n",
      "[356]\ttraining's rmse: 0.156499\tvalid_1's rmse: 0.641033\n",
      "[357]\ttraining's rmse: 0.15607\tvalid_1's rmse: 0.640999\n",
      "[358]\ttraining's rmse: 0.15585\tvalid_1's rmse: 0.640938\n",
      "[359]\ttraining's rmse: 0.155495\tvalid_1's rmse: 0.640923\n",
      "[360]\ttraining's rmse: 0.154828\tvalid_1's rmse: 0.640806\n",
      "[361]\ttraining's rmse: 0.15431\tvalid_1's rmse: 0.640704\n",
      "[362]\ttraining's rmse: 0.153865\tvalid_1's rmse: 0.640597\n",
      "[363]\ttraining's rmse: 0.153408\tvalid_1's rmse: 0.640538\n",
      "[364]\ttraining's rmse: 0.153082\tvalid_1's rmse: 0.640488\n",
      "[365]\ttraining's rmse: 0.152567\tvalid_1's rmse: 0.640378\n",
      "[366]\ttraining's rmse: 0.152101\tvalid_1's rmse: 0.640326\n",
      "[367]\ttraining's rmse: 0.151698\tvalid_1's rmse: 0.640309\n",
      "[368]\ttraining's rmse: 0.151286\tvalid_1's rmse: 0.640216\n",
      "[369]\ttraining's rmse: 0.150824\tvalid_1's rmse: 0.640112\n",
      "[370]\ttraining's rmse: 0.150388\tvalid_1's rmse: 0.640093\n",
      "[371]\ttraining's rmse: 0.150089\tvalid_1's rmse: 0.640048\n",
      "[372]\ttraining's rmse: 0.149846\tvalid_1's rmse: 0.640052\n",
      "[373]\ttraining's rmse: 0.149483\tvalid_1's rmse: 0.640063\n",
      "[374]\ttraining's rmse: 0.149139\tvalid_1's rmse: 0.639946\n",
      "[375]\ttraining's rmse: 0.148779\tvalid_1's rmse: 0.63985\n",
      "[376]\ttraining's rmse: 0.148579\tvalid_1's rmse: 0.639828\n",
      "[377]\ttraining's rmse: 0.148114\tvalid_1's rmse: 0.639717\n",
      "[378]\ttraining's rmse: 0.147789\tvalid_1's rmse: 0.639665\n",
      "[379]\ttraining's rmse: 0.147337\tvalid_1's rmse: 0.639579\n",
      "[380]\ttraining's rmse: 0.146883\tvalid_1's rmse: 0.639572\n",
      "[381]\ttraining's rmse: 0.146773\tvalid_1's rmse: 0.639534\n",
      "[382]\ttraining's rmse: 0.146237\tvalid_1's rmse: 0.639469\n",
      "[383]\ttraining's rmse: 0.145707\tvalid_1's rmse: 0.639387\n",
      "[384]\ttraining's rmse: 0.145362\tvalid_1's rmse: 0.639363\n",
      "[385]\ttraining's rmse: 0.144923\tvalid_1's rmse: 0.639327\n",
      "[386]\ttraining's rmse: 0.144401\tvalid_1's rmse: 0.63923\n",
      "[387]\ttraining's rmse: 0.143834\tvalid_1's rmse: 0.639076\n",
      "[388]\ttraining's rmse: 0.143542\tvalid_1's rmse: 0.638994\n",
      "[389]\ttraining's rmse: 0.143348\tvalid_1's rmse: 0.638974\n",
      "[390]\ttraining's rmse: 0.142936\tvalid_1's rmse: 0.638928\n",
      "[391]\ttraining's rmse: 0.142698\tvalid_1's rmse: 0.638873\n",
      "[392]\ttraining's rmse: 0.142424\tvalid_1's rmse: 0.638838\n",
      "[393]\ttraining's rmse: 0.141922\tvalid_1's rmse: 0.638826\n",
      "[394]\ttraining's rmse: 0.141618\tvalid_1's rmse: 0.638818\n",
      "[395]\ttraining's rmse: 0.141293\tvalid_1's rmse: 0.638781\n",
      "[396]\ttraining's rmse: 0.141058\tvalid_1's rmse: 0.63874\n",
      "[397]\ttraining's rmse: 0.140651\tvalid_1's rmse: 0.638723\n",
      "[398]\ttraining's rmse: 0.140159\tvalid_1's rmse: 0.63858\n",
      "[399]\ttraining's rmse: 0.139692\tvalid_1's rmse: 0.638494\n",
      "[400]\ttraining's rmse: 0.139464\tvalid_1's rmse: 0.638516\n",
      "[401]\ttraining's rmse: 0.139153\tvalid_1's rmse: 0.638471\n",
      "[402]\ttraining's rmse: 0.138706\tvalid_1's rmse: 0.638466\n",
      "[403]\ttraining's rmse: 0.138398\tvalid_1's rmse: 0.63844\n",
      "[404]\ttraining's rmse: 0.138082\tvalid_1's rmse: 0.638413\n",
      "[405]\ttraining's rmse: 0.137682\tvalid_1's rmse: 0.638337\n",
      "[406]\ttraining's rmse: 0.137229\tvalid_1's rmse: 0.638264\n",
      "[407]\ttraining's rmse: 0.136834\tvalid_1's rmse: 0.638236\n",
      "[408]\ttraining's rmse: 0.136552\tvalid_1's rmse: 0.638189\n",
      "[409]\ttraining's rmse: 0.136294\tvalid_1's rmse: 0.638153\n",
      "[410]\ttraining's rmse: 0.135895\tvalid_1's rmse: 0.638105\n",
      "[411]\ttraining's rmse: 0.135651\tvalid_1's rmse: 0.638049\n",
      "[412]\ttraining's rmse: 0.135221\tvalid_1's rmse: 0.638005\n",
      "[413]\ttraining's rmse: 0.134931\tvalid_1's rmse: 0.637939\n",
      "[414]\ttraining's rmse: 0.134461\tvalid_1's rmse: 0.63786\n",
      "[415]\ttraining's rmse: 0.134152\tvalid_1's rmse: 0.637904\n",
      "[416]\ttraining's rmse: 0.133644\tvalid_1's rmse: 0.637877\n",
      "[417]\ttraining's rmse: 0.133351\tvalid_1's rmse: 0.637898\n",
      "[418]\ttraining's rmse: 0.133235\tvalid_1's rmse: 0.637879\n",
      "[419]\ttraining's rmse: 0.133\tvalid_1's rmse: 0.637878\n",
      "[420]\ttraining's rmse: 0.132566\tvalid_1's rmse: 0.637847\n",
      "[421]\ttraining's rmse: 0.132225\tvalid_1's rmse: 0.637802\n",
      "[422]\ttraining's rmse: 0.131871\tvalid_1's rmse: 0.637775\n",
      "[423]\ttraining's rmse: 0.131415\tvalid_1's rmse: 0.637662\n",
      "[424]\ttraining's rmse: 0.131106\tvalid_1's rmse: 0.637616\n",
      "[425]\ttraining's rmse: 0.13076\tvalid_1's rmse: 0.637604\n",
      "[426]\ttraining's rmse: 0.130322\tvalid_1's rmse: 0.637511\n",
      "[427]\ttraining's rmse: 0.12991\tvalid_1's rmse: 0.637446\n",
      "[428]\ttraining's rmse: 0.129475\tvalid_1's rmse: 0.637379\n",
      "[429]\ttraining's rmse: 0.129291\tvalid_1's rmse: 0.637352\n",
      "[430]\ttraining's rmse: 0.128905\tvalid_1's rmse: 0.63731\n",
      "[431]\ttraining's rmse: 0.128531\tvalid_1's rmse: 0.637276\n",
      "[432]\ttraining's rmse: 0.128241\tvalid_1's rmse: 0.637251\n",
      "[433]\ttraining's rmse: 0.128048\tvalid_1's rmse: 0.637217\n",
      "[434]\ttraining's rmse: 0.127606\tvalid_1's rmse: 0.637167\n",
      "[435]\ttraining's rmse: 0.127128\tvalid_1's rmse: 0.637107\n",
      "[436]\ttraining's rmse: 0.126857\tvalid_1's rmse: 0.637074\n",
      "[437]\ttraining's rmse: 0.126751\tvalid_1's rmse: 0.637051\n",
      "[438]\ttraining's rmse: 0.126611\tvalid_1's rmse: 0.637002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439]\ttraining's rmse: 0.126353\tvalid_1's rmse: 0.636969\n",
      "[440]\ttraining's rmse: 0.126008\tvalid_1's rmse: 0.636894\n",
      "[441]\ttraining's rmse: 0.125773\tvalid_1's rmse: 0.636868\n",
      "[442]\ttraining's rmse: 0.125534\tvalid_1's rmse: 0.63684\n",
      "[443]\ttraining's rmse: 0.125293\tvalid_1's rmse: 0.636795\n",
      "[444]\ttraining's rmse: 0.124959\tvalid_1's rmse: 0.636767\n",
      "[445]\ttraining's rmse: 0.124759\tvalid_1's rmse: 0.636766\n",
      "[446]\ttraining's rmse: 0.124478\tvalid_1's rmse: 0.636732\n",
      "[447]\ttraining's rmse: 0.124263\tvalid_1's rmse: 0.636712\n",
      "[448]\ttraining's rmse: 0.124131\tvalid_1's rmse: 0.636692\n",
      "[449]\ttraining's rmse: 0.123657\tvalid_1's rmse: 0.636601\n",
      "[450]\ttraining's rmse: 0.12351\tvalid_1's rmse: 0.636582\n",
      "[451]\ttraining's rmse: 0.123094\tvalid_1's rmse: 0.636531\n",
      "[452]\ttraining's rmse: 0.122792\tvalid_1's rmse: 0.63649\n",
      "[453]\ttraining's rmse: 0.122415\tvalid_1's rmse: 0.636437\n",
      "[454]\ttraining's rmse: 0.122107\tvalid_1's rmse: 0.636379\n",
      "[455]\ttraining's rmse: 0.121762\tvalid_1's rmse: 0.636341\n",
      "[456]\ttraining's rmse: 0.121453\tvalid_1's rmse: 0.636281\n",
      "[457]\ttraining's rmse: 0.121208\tvalid_1's rmse: 0.636214\n",
      "[458]\ttraining's rmse: 0.121101\tvalid_1's rmse: 0.636197\n",
      "[459]\ttraining's rmse: 0.120664\tvalid_1's rmse: 0.636106\n",
      "[460]\ttraining's rmse: 0.120371\tvalid_1's rmse: 0.636071\n",
      "[461]\ttraining's rmse: 0.120019\tvalid_1's rmse: 0.63609\n",
      "[462]\ttraining's rmse: 0.119721\tvalid_1's rmse: 0.636047\n",
      "[463]\ttraining's rmse: 0.119496\tvalid_1's rmse: 0.636021\n",
      "[464]\ttraining's rmse: 0.119199\tvalid_1's rmse: 0.635935\n",
      "[465]\ttraining's rmse: 0.118822\tvalid_1's rmse: 0.63588\n",
      "[466]\ttraining's rmse: 0.118484\tvalid_1's rmse: 0.635844\n",
      "[467]\ttraining's rmse: 0.118141\tvalid_1's rmse: 0.635828\n",
      "[468]\ttraining's rmse: 0.11797\tvalid_1's rmse: 0.635819\n",
      "[469]\ttraining's rmse: 0.117581\tvalid_1's rmse: 0.63576\n",
      "[470]\ttraining's rmse: 0.117332\tvalid_1's rmse: 0.635712\n",
      "[471]\ttraining's rmse: 0.117141\tvalid_1's rmse: 0.635679\n",
      "[472]\ttraining's rmse: 0.116783\tvalid_1's rmse: 0.635647\n",
      "[473]\ttraining's rmse: 0.116624\tvalid_1's rmse: 0.635638\n",
      "[474]\ttraining's rmse: 0.116422\tvalid_1's rmse: 0.635624\n",
      "[475]\ttraining's rmse: 0.116347\tvalid_1's rmse: 0.635627\n",
      "[476]\ttraining's rmse: 0.115957\tvalid_1's rmse: 0.635597\n",
      "[477]\ttraining's rmse: 0.115669\tvalid_1's rmse: 0.635571\n",
      "[478]\ttraining's rmse: 0.115571\tvalid_1's rmse: 0.635545\n",
      "[479]\ttraining's rmse: 0.115292\tvalid_1's rmse: 0.635559\n",
      "[480]\ttraining's rmse: 0.115018\tvalid_1's rmse: 0.635576\n",
      "[481]\ttraining's rmse: 0.114736\tvalid_1's rmse: 0.635543\n",
      "[482]\ttraining's rmse: 0.114381\tvalid_1's rmse: 0.635422\n",
      "[483]\ttraining's rmse: 0.114067\tvalid_1's rmse: 0.63539\n",
      "[484]\ttraining's rmse: 0.113825\tvalid_1's rmse: 0.635354\n",
      "[485]\ttraining's rmse: 0.113696\tvalid_1's rmse: 0.635318\n",
      "[486]\ttraining's rmse: 0.113355\tvalid_1's rmse: 0.6353\n",
      "[487]\ttraining's rmse: 0.112979\tvalid_1's rmse: 0.635277\n",
      "[488]\ttraining's rmse: 0.112722\tvalid_1's rmse: 0.635256\n",
      "[489]\ttraining's rmse: 0.112435\tvalid_1's rmse: 0.635226\n",
      "[490]\ttraining's rmse: 0.112093\tvalid_1's rmse: 0.635158\n",
      "[491]\ttraining's rmse: 0.111776\tvalid_1's rmse: 0.635138\n",
      "[492]\ttraining's rmse: 0.111611\tvalid_1's rmse: 0.635106\n",
      "[493]\ttraining's rmse: 0.111375\tvalid_1's rmse: 0.635065\n",
      "[494]\ttraining's rmse: 0.11108\tvalid_1's rmse: 0.635025\n",
      "[495]\ttraining's rmse: 0.110713\tvalid_1's rmse: 0.634993\n",
      "[496]\ttraining's rmse: 0.110382\tvalid_1's rmse: 0.634975\n",
      "[497]\ttraining's rmse: 0.110193\tvalid_1's rmse: 0.634953\n",
      "[498]\ttraining's rmse: 0.109819\tvalid_1's rmse: 0.634902\n",
      "[499]\ttraining's rmse: 0.109516\tvalid_1's rmse: 0.634831\n",
      "[500]\ttraining's rmse: 0.1092\tvalid_1's rmse: 0.634788\n",
      "[501]\ttraining's rmse: 0.108911\tvalid_1's rmse: 0.634737\n",
      "[502]\ttraining's rmse: 0.108643\tvalid_1's rmse: 0.634731\n",
      "[503]\ttraining's rmse: 0.108306\tvalid_1's rmse: 0.634685\n",
      "[504]\ttraining's rmse: 0.108065\tvalid_1's rmse: 0.634618\n",
      "[505]\ttraining's rmse: 0.107759\tvalid_1's rmse: 0.634584\n",
      "[506]\ttraining's rmse: 0.107503\tvalid_1's rmse: 0.634557\n",
      "[507]\ttraining's rmse: 0.107257\tvalid_1's rmse: 0.634551\n",
      "[508]\ttraining's rmse: 0.106934\tvalid_1's rmse: 0.634497\n",
      "[509]\ttraining's rmse: 0.106645\tvalid_1's rmse: 0.634486\n",
      "[510]\ttraining's rmse: 0.106352\tvalid_1's rmse: 0.634444\n",
      "[511]\ttraining's rmse: 0.106228\tvalid_1's rmse: 0.63441\n",
      "[512]\ttraining's rmse: 0.106114\tvalid_1's rmse: 0.634403\n",
      "[513]\ttraining's rmse: 0.105786\tvalid_1's rmse: 0.634325\n",
      "[514]\ttraining's rmse: 0.105544\tvalid_1's rmse: 0.634307\n",
      "[515]\ttraining's rmse: 0.10528\tvalid_1's rmse: 0.634293\n",
      "[516]\ttraining's rmse: 0.105174\tvalid_1's rmse: 0.634288\n",
      "[517]\ttraining's rmse: 0.105029\tvalid_1's rmse: 0.634246\n",
      "[518]\ttraining's rmse: 0.10475\tvalid_1's rmse: 0.634203\n",
      "[519]\ttraining's rmse: 0.104571\tvalid_1's rmse: 0.634197\n",
      "[520]\ttraining's rmse: 0.104425\tvalid_1's rmse: 0.634191\n",
      "[521]\ttraining's rmse: 0.104156\tvalid_1's rmse: 0.63414\n",
      "[522]\ttraining's rmse: 0.103914\tvalid_1's rmse: 0.634078\n",
      "[523]\ttraining's rmse: 0.103693\tvalid_1's rmse: 0.634053\n",
      "[524]\ttraining's rmse: 0.103564\tvalid_1's rmse: 0.634052\n",
      "[525]\ttraining's rmse: 0.103311\tvalid_1's rmse: 0.634056\n",
      "[526]\ttraining's rmse: 0.103091\tvalid_1's rmse: 0.634015\n",
      "[527]\ttraining's rmse: 0.102935\tvalid_1's rmse: 0.633976\n",
      "[528]\ttraining's rmse: 0.102666\tvalid_1's rmse: 0.63394\n",
      "[529]\ttraining's rmse: 0.102464\tvalid_1's rmse: 0.633902\n",
      "[530]\ttraining's rmse: 0.102248\tvalid_1's rmse: 0.633883\n",
      "[531]\ttraining's rmse: 0.102037\tvalid_1's rmse: 0.63383\n",
      "[532]\ttraining's rmse: 0.10181\tvalid_1's rmse: 0.63381\n",
      "[533]\ttraining's rmse: 0.101569\tvalid_1's rmse: 0.633807\n",
      "[534]\ttraining's rmse: 0.101373\tvalid_1's rmse: 0.633758\n",
      "[535]\ttraining's rmse: 0.101154\tvalid_1's rmse: 0.633767\n",
      "[536]\ttraining's rmse: 0.10091\tvalid_1's rmse: 0.633681\n",
      "[537]\ttraining's rmse: 0.100694\tvalid_1's rmse: 0.633641\n",
      "[538]\ttraining's rmse: 0.100472\tvalid_1's rmse: 0.633595\n",
      "[539]\ttraining's rmse: 0.100256\tvalid_1's rmse: 0.633591\n",
      "[540]\ttraining's rmse: 0.100002\tvalid_1's rmse: 0.633592\n",
      "[541]\ttraining's rmse: 0.0997448\tvalid_1's rmse: 0.633525\n",
      "[542]\ttraining's rmse: 0.0995115\tvalid_1's rmse: 0.633491\n",
      "[543]\ttraining's rmse: 0.0993697\tvalid_1's rmse: 0.633481\n",
      "[544]\ttraining's rmse: 0.0992159\tvalid_1's rmse: 0.633501\n",
      "[545]\ttraining's rmse: 0.0989797\tvalid_1's rmse: 0.633475\n",
      "[546]\ttraining's rmse: 0.0987972\tvalid_1's rmse: 0.633498\n",
      "[547]\ttraining's rmse: 0.0985398\tvalid_1's rmse: 0.633465\n",
      "[548]\ttraining's rmse: 0.0983469\tvalid_1's rmse: 0.633429\n",
      "[549]\ttraining's rmse: 0.0980914\tvalid_1's rmse: 0.633411\n",
      "[550]\ttraining's rmse: 0.0978645\tvalid_1's rmse: 0.63338\n",
      "[551]\ttraining's rmse: 0.0977921\tvalid_1's rmse: 0.633366\n",
      "[552]\ttraining's rmse: 0.0974794\tvalid_1's rmse: 0.63332\n",
      "[553]\ttraining's rmse: 0.0972491\tvalid_1's rmse: 0.633303\n",
      "[554]\ttraining's rmse: 0.096966\tvalid_1's rmse: 0.633284\n",
      "[555]\ttraining's rmse: 0.0968278\tvalid_1's rmse: 0.633292\n",
      "[556]\ttraining's rmse: 0.0966197\tvalid_1's rmse: 0.63327\n",
      "[557]\ttraining's rmse: 0.0964562\tvalid_1's rmse: 0.633241\n",
      "[558]\ttraining's rmse: 0.0962215\tvalid_1's rmse: 0.633224\n",
      "[559]\ttraining's rmse: 0.0961293\tvalid_1's rmse: 0.633217\n",
      "[560]\ttraining's rmse: 0.0959276\tvalid_1's rmse: 0.63321\n",
      "[561]\ttraining's rmse: 0.0956929\tvalid_1's rmse: 0.633202\n",
      "[562]\ttraining's rmse: 0.0954767\tvalid_1's rmse: 0.633214\n",
      "[563]\ttraining's rmse: 0.0952769\tvalid_1's rmse: 0.633205\n",
      "[564]\ttraining's rmse: 0.095063\tvalid_1's rmse: 0.633163\n",
      "[565]\ttraining's rmse: 0.0948194\tvalid_1's rmse: 0.633161\n",
      "[566]\ttraining's rmse: 0.0947046\tvalid_1's rmse: 0.633152\n",
      "[567]\ttraining's rmse: 0.0946297\tvalid_1's rmse: 0.633135\n",
      "[568]\ttraining's rmse: 0.0945149\tvalid_1's rmse: 0.633116\n",
      "[569]\ttraining's rmse: 0.0942864\tvalid_1's rmse: 0.633098\n",
      "[570]\ttraining's rmse: 0.0940626\tvalid_1's rmse: 0.633076\n",
      "[571]\ttraining's rmse: 0.0938536\tvalid_1's rmse: 0.633044\n",
      "[572]\ttraining's rmse: 0.0936783\tvalid_1's rmse: 0.633023\n",
      "[573]\ttraining's rmse: 0.0934897\tvalid_1's rmse: 0.632988\n",
      "[574]\ttraining's rmse: 0.0932578\tvalid_1's rmse: 0.632989\n",
      "[575]\ttraining's rmse: 0.0930175\tvalid_1's rmse: 0.632976\n",
      "[576]\ttraining's rmse: 0.0929362\tvalid_1's rmse: 0.632971\n",
      "[577]\ttraining's rmse: 0.0927078\tvalid_1's rmse: 0.632938\n",
      "[578]\ttraining's rmse: 0.0924224\tvalid_1's rmse: 0.632894\n",
      "[579]\ttraining's rmse: 0.0921321\tvalid_1's rmse: 0.632835\n",
      "[580]\ttraining's rmse: 0.0918383\tvalid_1's rmse: 0.632781\n",
      "[581]\ttraining's rmse: 0.0917134\tvalid_1's rmse: 0.632765\n",
      "[582]\ttraining's rmse: 0.0915881\tvalid_1's rmse: 0.632746\n",
      "[583]\ttraining's rmse: 0.0915171\tvalid_1's rmse: 0.632743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[584]\ttraining's rmse: 0.0913997\tvalid_1's rmse: 0.632721\n",
      "[585]\ttraining's rmse: 0.0911527\tvalid_1's rmse: 0.632722\n",
      "[586]\ttraining's rmse: 0.091092\tvalid_1's rmse: 0.632725\n",
      "[587]\ttraining's rmse: 0.0908627\tvalid_1's rmse: 0.632683\n",
      "[588]\ttraining's rmse: 0.0906124\tvalid_1's rmse: 0.632651\n",
      "[589]\ttraining's rmse: 0.0904244\tvalid_1's rmse: 0.63265\n",
      "[590]\ttraining's rmse: 0.0903315\tvalid_1's rmse: 0.632609\n",
      "[591]\ttraining's rmse: 0.090116\tvalid_1's rmse: 0.632582\n",
      "[592]\ttraining's rmse: 0.0899129\tvalid_1's rmse: 0.632604\n",
      "[593]\ttraining's rmse: 0.0897307\tvalid_1's rmse: 0.632561\n",
      "[594]\ttraining's rmse: 0.0894875\tvalid_1's rmse: 0.632524\n",
      "[595]\ttraining's rmse: 0.089337\tvalid_1's rmse: 0.632514\n",
      "[596]\ttraining's rmse: 0.0891192\tvalid_1's rmse: 0.632491\n",
      "[597]\ttraining's rmse: 0.0888843\tvalid_1's rmse: 0.632449\n",
      "[598]\ttraining's rmse: 0.0887567\tvalid_1's rmse: 0.632446\n",
      "[599]\ttraining's rmse: 0.0885813\tvalid_1's rmse: 0.632411\n",
      "[600]\ttraining's rmse: 0.0883601\tvalid_1's rmse: 0.632379\n",
      "[601]\ttraining's rmse: 0.0881876\tvalid_1's rmse: 0.632353\n",
      "[602]\ttraining's rmse: 0.0879872\tvalid_1's rmse: 0.632333\n",
      "[603]\ttraining's rmse: 0.0878151\tvalid_1's rmse: 0.63234\n",
      "[604]\ttraining's rmse: 0.0876558\tvalid_1's rmse: 0.632318\n",
      "[605]\ttraining's rmse: 0.0874334\tvalid_1's rmse: 0.632308\n",
      "[606]\ttraining's rmse: 0.0872718\tvalid_1's rmse: 0.632282\n",
      "[607]\ttraining's rmse: 0.0871439\tvalid_1's rmse: 0.632258\n",
      "[608]\ttraining's rmse: 0.0870137\tvalid_1's rmse: 0.632221\n",
      "[609]\ttraining's rmse: 0.0869229\tvalid_1's rmse: 0.6322\n",
      "[610]\ttraining's rmse: 0.0867878\tvalid_1's rmse: 0.632188\n",
      "[611]\ttraining's rmse: 0.0866088\tvalid_1's rmse: 0.632183\n",
      "[612]\ttraining's rmse: 0.0863738\tvalid_1's rmse: 0.632176\n",
      "[613]\ttraining's rmse: 0.0861872\tvalid_1's rmse: 0.632148\n",
      "[614]\ttraining's rmse: 0.0860375\tvalid_1's rmse: 0.632153\n",
      "[615]\ttraining's rmse: 0.085878\tvalid_1's rmse: 0.632126\n",
      "[616]\ttraining's rmse: 0.0856897\tvalid_1's rmse: 0.632103\n",
      "[617]\ttraining's rmse: 0.0854881\tvalid_1's rmse: 0.632103\n",
      "[618]\ttraining's rmse: 0.085307\tvalid_1's rmse: 0.632095\n",
      "[619]\ttraining's rmse: 0.0851709\tvalid_1's rmse: 0.632076\n",
      "[620]\ttraining's rmse: 0.0850111\tvalid_1's rmse: 0.632056\n",
      "[621]\ttraining's rmse: 0.0848148\tvalid_1's rmse: 0.632024\n",
      "[622]\ttraining's rmse: 0.0846582\tvalid_1's rmse: 0.632026\n",
      "[623]\ttraining's rmse: 0.0844475\tvalid_1's rmse: 0.63201\n",
      "[624]\ttraining's rmse: 0.0842468\tvalid_1's rmse: 0.632006\n",
      "[625]\ttraining's rmse: 0.0840249\tvalid_1's rmse: 0.631954\n",
      "[626]\ttraining's rmse: 0.0838524\tvalid_1's rmse: 0.631923\n",
      "[627]\ttraining's rmse: 0.0836874\tvalid_1's rmse: 0.631909\n",
      "[628]\ttraining's rmse: 0.0835301\tvalid_1's rmse: 0.631855\n",
      "[629]\ttraining's rmse: 0.083394\tvalid_1's rmse: 0.631848\n",
      "[630]\ttraining's rmse: 0.0831783\tvalid_1's rmse: 0.631828\n",
      "[631]\ttraining's rmse: 0.0830286\tvalid_1's rmse: 0.631802\n",
      "[632]\ttraining's rmse: 0.0829494\tvalid_1's rmse: 0.6318\n",
      "[633]\ttraining's rmse: 0.0827936\tvalid_1's rmse: 0.631796\n",
      "[634]\ttraining's rmse: 0.082658\tvalid_1's rmse: 0.63178\n",
      "[635]\ttraining's rmse: 0.0825024\tvalid_1's rmse: 0.631759\n",
      "[636]\ttraining's rmse: 0.0824088\tvalid_1's rmse: 0.631753\n",
      "[637]\ttraining's rmse: 0.0823129\tvalid_1's rmse: 0.631735\n",
      "[638]\ttraining's rmse: 0.082129\tvalid_1's rmse: 0.631738\n",
      "[639]\ttraining's rmse: 0.0819705\tvalid_1's rmse: 0.631715\n",
      "[640]\ttraining's rmse: 0.0817595\tvalid_1's rmse: 0.631705\n",
      "[641]\ttraining's rmse: 0.081658\tvalid_1's rmse: 0.631682\n",
      "[642]\ttraining's rmse: 0.0815519\tvalid_1's rmse: 0.631671\n",
      "[643]\ttraining's rmse: 0.0814041\tvalid_1's rmse: 0.631676\n",
      "[644]\ttraining's rmse: 0.0811874\tvalid_1's rmse: 0.631664\n",
      "[645]\ttraining's rmse: 0.0809875\tvalid_1's rmse: 0.631648\n",
      "[646]\ttraining's rmse: 0.0807931\tvalid_1's rmse: 0.631648\n",
      "[647]\ttraining's rmse: 0.0806854\tvalid_1's rmse: 0.631628\n",
      "[648]\ttraining's rmse: 0.0805419\tvalid_1's rmse: 0.63161\n",
      "[649]\ttraining's rmse: 0.080334\tvalid_1's rmse: 0.631623\n",
      "[650]\ttraining's rmse: 0.0801394\tvalid_1's rmse: 0.631601\n",
      "[651]\ttraining's rmse: 0.0800183\tvalid_1's rmse: 0.631589\n",
      "[652]\ttraining's rmse: 0.0798544\tvalid_1's rmse: 0.631568\n",
      "[653]\ttraining's rmse: 0.0797701\tvalid_1's rmse: 0.631559\n",
      "[654]\ttraining's rmse: 0.0796721\tvalid_1's rmse: 0.631551\n",
      "[655]\ttraining's rmse: 0.0795066\tvalid_1's rmse: 0.631521\n",
      "[656]\ttraining's rmse: 0.0794062\tvalid_1's rmse: 0.631513\n",
      "[657]\ttraining's rmse: 0.0792394\tvalid_1's rmse: 0.631481\n",
      "[658]\ttraining's rmse: 0.079105\tvalid_1's rmse: 0.631472\n",
      "[659]\ttraining's rmse: 0.0789633\tvalid_1's rmse: 0.631453\n",
      "[660]\ttraining's rmse: 0.0787947\tvalid_1's rmse: 0.631425\n",
      "[661]\ttraining's rmse: 0.078725\tvalid_1's rmse: 0.631424\n",
      "[662]\ttraining's rmse: 0.0785577\tvalid_1's rmse: 0.631416\n",
      "[663]\ttraining's rmse: 0.0784095\tvalid_1's rmse: 0.631433\n",
      "[664]\ttraining's rmse: 0.0783254\tvalid_1's rmse: 0.631424\n",
      "[665]\ttraining's rmse: 0.0782594\tvalid_1's rmse: 0.631415\n",
      "[666]\ttraining's rmse: 0.0781416\tvalid_1's rmse: 0.631389\n",
      "[667]\ttraining's rmse: 0.0779985\tvalid_1's rmse: 0.631383\n",
      "[668]\ttraining's rmse: 0.0778557\tvalid_1's rmse: 0.631376\n",
      "[669]\ttraining's rmse: 0.0776975\tvalid_1's rmse: 0.631373\n",
      "[670]\ttraining's rmse: 0.0775322\tvalid_1's rmse: 0.631364\n",
      "[671]\ttraining's rmse: 0.0774017\tvalid_1's rmse: 0.631344\n",
      "[672]\ttraining's rmse: 0.0772344\tvalid_1's rmse: 0.631355\n",
      "[673]\ttraining's rmse: 0.0770961\tvalid_1's rmse: 0.631364\n",
      "[674]\ttraining's rmse: 0.0769394\tvalid_1's rmse: 0.631363\n",
      "[675]\ttraining's rmse: 0.0767745\tvalid_1's rmse: 0.63135\n",
      "[676]\ttraining's rmse: 0.0766423\tvalid_1's rmse: 0.631353\n",
      "[677]\ttraining's rmse: 0.0764542\tvalid_1's rmse: 0.631356\n",
      "[678]\ttraining's rmse: 0.0763631\tvalid_1's rmse: 0.631351\n",
      "[679]\ttraining's rmse: 0.076196\tvalid_1's rmse: 0.631335\n",
      "[680]\ttraining's rmse: 0.0760097\tvalid_1's rmse: 0.631274\n",
      "[681]\ttraining's rmse: 0.0758624\tvalid_1's rmse: 0.631245\n",
      "[682]\ttraining's rmse: 0.0756994\tvalid_1's rmse: 0.63122\n",
      "[683]\ttraining's rmse: 0.0755211\tvalid_1's rmse: 0.631197\n",
      "[684]\ttraining's rmse: 0.0753678\tvalid_1's rmse: 0.631187\n",
      "[685]\ttraining's rmse: 0.0752984\tvalid_1's rmse: 0.631182\n",
      "[686]\ttraining's rmse: 0.0751951\tvalid_1's rmse: 0.631174\n",
      "[687]\ttraining's rmse: 0.0751205\tvalid_1's rmse: 0.631172\n",
      "[688]\ttraining's rmse: 0.0750237\tvalid_1's rmse: 0.631165\n",
      "[689]\ttraining's rmse: 0.0748947\tvalid_1's rmse: 0.63115\n",
      "[690]\ttraining's rmse: 0.074762\tvalid_1's rmse: 0.631152\n",
      "[691]\ttraining's rmse: 0.0746793\tvalid_1's rmse: 0.631153\n",
      "[692]\ttraining's rmse: 0.0746053\tvalid_1's rmse: 0.631121\n",
      "[693]\ttraining's rmse: 0.0744227\tvalid_1's rmse: 0.631108\n",
      "[694]\ttraining's rmse: 0.074284\tvalid_1's rmse: 0.631108\n",
      "[695]\ttraining's rmse: 0.0741506\tvalid_1's rmse: 0.6311\n",
      "[696]\ttraining's rmse: 0.0739453\tvalid_1's rmse: 0.631053\n",
      "[697]\ttraining's rmse: 0.0737756\tvalid_1's rmse: 0.631042\n",
      "[698]\ttraining's rmse: 0.0737068\tvalid_1's rmse: 0.631032\n",
      "[699]\ttraining's rmse: 0.0735636\tvalid_1's rmse: 0.631038\n",
      "[700]\ttraining's rmse: 0.0734259\tvalid_1's rmse: 0.631025\n",
      "[701]\ttraining's rmse: 0.0732683\tvalid_1's rmse: 0.631027\n",
      "[702]\ttraining's rmse: 0.0731571\tvalid_1's rmse: 0.631025\n",
      "[703]\ttraining's rmse: 0.0730323\tvalid_1's rmse: 0.631031\n",
      "[704]\ttraining's rmse: 0.0729226\tvalid_1's rmse: 0.631043\n",
      "[705]\ttraining's rmse: 0.0727852\tvalid_1's rmse: 0.631039\n",
      "[706]\ttraining's rmse: 0.0726872\tvalid_1's rmse: 0.631018\n",
      "[707]\ttraining's rmse: 0.0725259\tvalid_1's rmse: 0.631\n",
      "[708]\ttraining's rmse: 0.0724453\tvalid_1's rmse: 0.631001\n",
      "[709]\ttraining's rmse: 0.0723147\tvalid_1's rmse: 0.630997\n",
      "[710]\ttraining's rmse: 0.0721916\tvalid_1's rmse: 0.630985\n",
      "[711]\ttraining's rmse: 0.072056\tvalid_1's rmse: 0.63098\n",
      "[712]\ttraining's rmse: 0.0719618\tvalid_1's rmse: 0.630985\n",
      "[713]\ttraining's rmse: 0.0718563\tvalid_1's rmse: 0.630963\n",
      "[714]\ttraining's rmse: 0.0716711\tvalid_1's rmse: 0.630945\n",
      "[715]\ttraining's rmse: 0.0715331\tvalid_1's rmse: 0.630925\n",
      "[716]\ttraining's rmse: 0.0714279\tvalid_1's rmse: 0.630919\n",
      "[717]\ttraining's rmse: 0.0713261\tvalid_1's rmse: 0.630893\n",
      "[718]\ttraining's rmse: 0.0711408\tvalid_1's rmse: 0.630864\n",
      "[719]\ttraining's rmse: 0.0710557\tvalid_1's rmse: 0.630865\n",
      "[720]\ttraining's rmse: 0.0709376\tvalid_1's rmse: 0.630861\n",
      "[721]\ttraining's rmse: 0.0707816\tvalid_1's rmse: 0.63085\n",
      "[722]\ttraining's rmse: 0.070665\tvalid_1's rmse: 0.63084\n",
      "[723]\ttraining's rmse: 0.0705198\tvalid_1's rmse: 0.630836\n",
      "[724]\ttraining's rmse: 0.0703739\tvalid_1's rmse: 0.630828\n",
      "[725]\ttraining's rmse: 0.0701821\tvalid_1's rmse: 0.630811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[726]\ttraining's rmse: 0.07012\tvalid_1's rmse: 0.630798\n",
      "[727]\ttraining's rmse: 0.0700566\tvalid_1's rmse: 0.630786\n",
      "[728]\ttraining's rmse: 0.0699012\tvalid_1's rmse: 0.630761\n",
      "[729]\ttraining's rmse: 0.0697802\tvalid_1's rmse: 0.630748\n",
      "[730]\ttraining's rmse: 0.0696102\tvalid_1's rmse: 0.630716\n",
      "[731]\ttraining's rmse: 0.0694943\tvalid_1's rmse: 0.630721\n",
      "[732]\ttraining's rmse: 0.0693503\tvalid_1's rmse: 0.630718\n",
      "[733]\ttraining's rmse: 0.0692184\tvalid_1's rmse: 0.630703\n",
      "[734]\ttraining's rmse: 0.0690591\tvalid_1's rmse: 0.630679\n",
      "[735]\ttraining's rmse: 0.068914\tvalid_1's rmse: 0.630656\n",
      "[736]\ttraining's rmse: 0.0687691\tvalid_1's rmse: 0.630647\n",
      "[737]\ttraining's rmse: 0.0686208\tvalid_1's rmse: 0.630624\n",
      "[738]\ttraining's rmse: 0.0685145\tvalid_1's rmse: 0.63061\n",
      "[739]\ttraining's rmse: 0.0683628\tvalid_1's rmse: 0.630596\n",
      "[740]\ttraining's rmse: 0.0682342\tvalid_1's rmse: 0.630597\n",
      "[741]\ttraining's rmse: 0.0680876\tvalid_1's rmse: 0.630562\n",
      "[742]\ttraining's rmse: 0.068014\tvalid_1's rmse: 0.630563\n",
      "[743]\ttraining's rmse: 0.0678754\tvalid_1's rmse: 0.630551\n",
      "[744]\ttraining's rmse: 0.0677611\tvalid_1's rmse: 0.630552\n",
      "[745]\ttraining's rmse: 0.0676253\tvalid_1's rmse: 0.630542\n",
      "[746]\ttraining's rmse: 0.0674918\tvalid_1's rmse: 0.630524\n",
      "[747]\ttraining's rmse: 0.0674076\tvalid_1's rmse: 0.630523\n",
      "[748]\ttraining's rmse: 0.0672867\tvalid_1's rmse: 0.630512\n",
      "[749]\ttraining's rmse: 0.0671042\tvalid_1's rmse: 0.630514\n",
      "[750]\ttraining's rmse: 0.0669699\tvalid_1's rmse: 0.630507\n",
      "[751]\ttraining's rmse: 0.0668655\tvalid_1's rmse: 0.630486\n",
      "[752]\ttraining's rmse: 0.06673\tvalid_1's rmse: 0.630483\n",
      "[753]\ttraining's rmse: 0.0666076\tvalid_1's rmse: 0.630476\n",
      "[754]\ttraining's rmse: 0.0664692\tvalid_1's rmse: 0.630473\n",
      "[755]\ttraining's rmse: 0.0663405\tvalid_1's rmse: 0.63045\n",
      "[756]\ttraining's rmse: 0.0662179\tvalid_1's rmse: 0.630451\n",
      "[757]\ttraining's rmse: 0.0661363\tvalid_1's rmse: 0.63043\n",
      "[758]\ttraining's rmse: 0.0659817\tvalid_1's rmse: 0.630413\n",
      "[759]\ttraining's rmse: 0.0658934\tvalid_1's rmse: 0.630397\n",
      "[760]\ttraining's rmse: 0.0658152\tvalid_1's rmse: 0.630396\n",
      "[761]\ttraining's rmse: 0.0657044\tvalid_1's rmse: 0.630391\n",
      "[762]\ttraining's rmse: 0.0655674\tvalid_1's rmse: 0.630379\n",
      "[763]\ttraining's rmse: 0.0654066\tvalid_1's rmse: 0.630385\n",
      "[764]\ttraining's rmse: 0.0653257\tvalid_1's rmse: 0.630376\n",
      "[765]\ttraining's rmse: 0.0652117\tvalid_1's rmse: 0.630374\n",
      "[766]\ttraining's rmse: 0.0651155\tvalid_1's rmse: 0.630368\n",
      "[767]\ttraining's rmse: 0.0650155\tvalid_1's rmse: 0.630352\n",
      "[768]\ttraining's rmse: 0.0649502\tvalid_1's rmse: 0.630345\n",
      "[769]\ttraining's rmse: 0.0648818\tvalid_1's rmse: 0.630331\n",
      "[770]\ttraining's rmse: 0.0647845\tvalid_1's rmse: 0.630329\n",
      "[771]\ttraining's rmse: 0.0646523\tvalid_1's rmse: 0.630313\n",
      "[772]\ttraining's rmse: 0.0645125\tvalid_1's rmse: 0.630306\n",
      "[773]\ttraining's rmse: 0.0644052\tvalid_1's rmse: 0.630307\n",
      "[774]\ttraining's rmse: 0.0642928\tvalid_1's rmse: 0.630288\n",
      "[775]\ttraining's rmse: 0.0641833\tvalid_1's rmse: 0.630287\n",
      "[776]\ttraining's rmse: 0.0640726\tvalid_1's rmse: 0.630273\n",
      "[777]\ttraining's rmse: 0.0640055\tvalid_1's rmse: 0.630266\n",
      "[778]\ttraining's rmse: 0.0638589\tvalid_1's rmse: 0.630242\n",
      "[779]\ttraining's rmse: 0.0637993\tvalid_1's rmse: 0.630245\n",
      "[780]\ttraining's rmse: 0.0637243\tvalid_1's rmse: 0.630236\n",
      "[781]\ttraining's rmse: 0.0636529\tvalid_1's rmse: 0.630232\n",
      "[782]\ttraining's rmse: 0.0635204\tvalid_1's rmse: 0.630229\n",
      "[783]\ttraining's rmse: 0.0633836\tvalid_1's rmse: 0.630232\n",
      "[784]\ttraining's rmse: 0.0632658\tvalid_1's rmse: 0.630209\n",
      "[785]\ttraining's rmse: 0.0631875\tvalid_1's rmse: 0.630197\n",
      "[786]\ttraining's rmse: 0.0630876\tvalid_1's rmse: 0.630189\n",
      "[787]\ttraining's rmse: 0.0630189\tvalid_1's rmse: 0.630165\n",
      "[788]\ttraining's rmse: 0.0629304\tvalid_1's rmse: 0.630142\n",
      "[789]\ttraining's rmse: 0.0628391\tvalid_1's rmse: 0.630144\n",
      "[790]\ttraining's rmse: 0.0627211\tvalid_1's rmse: 0.630129\n",
      "[791]\ttraining's rmse: 0.0625956\tvalid_1's rmse: 0.630094\n",
      "[792]\ttraining's rmse: 0.0624851\tvalid_1's rmse: 0.630087\n",
      "[793]\ttraining's rmse: 0.0623566\tvalid_1's rmse: 0.630078\n",
      "[794]\ttraining's rmse: 0.0622793\tvalid_1's rmse: 0.630066\n",
      "[795]\ttraining's rmse: 0.0621973\tvalid_1's rmse: 0.630064\n",
      "[796]\ttraining's rmse: 0.0620867\tvalid_1's rmse: 0.630048\n",
      "[797]\ttraining's rmse: 0.0619902\tvalid_1's rmse: 0.630042\n",
      "[798]\ttraining's rmse: 0.0618817\tvalid_1's rmse: 0.630027\n",
      "[799]\ttraining's rmse: 0.0618028\tvalid_1's rmse: 0.63003\n",
      "[800]\ttraining's rmse: 0.0616858\tvalid_1's rmse: 0.630033\n",
      "[801]\ttraining's rmse: 0.0616076\tvalid_1's rmse: 0.630016\n",
      "[802]\ttraining's rmse: 0.0614949\tvalid_1's rmse: 0.630008\n",
      "[803]\ttraining's rmse: 0.061425\tvalid_1's rmse: 0.629994\n",
      "[804]\ttraining's rmse: 0.0613146\tvalid_1's rmse: 0.629994\n",
      "[805]\ttraining's rmse: 0.0612637\tvalid_1's rmse: 0.62998\n",
      "[806]\ttraining's rmse: 0.061155\tvalid_1's rmse: 0.629968\n",
      "[807]\ttraining's rmse: 0.0610366\tvalid_1's rmse: 0.629965\n",
      "[808]\ttraining's rmse: 0.0609039\tvalid_1's rmse: 0.629957\n",
      "[809]\ttraining's rmse: 0.0608103\tvalid_1's rmse: 0.629938\n",
      "[810]\ttraining's rmse: 0.0607425\tvalid_1's rmse: 0.62993\n",
      "[811]\ttraining's rmse: 0.0606717\tvalid_1's rmse: 0.629932\n",
      "[812]\ttraining's rmse: 0.0605789\tvalid_1's rmse: 0.62994\n",
      "[813]\ttraining's rmse: 0.0604984\tvalid_1's rmse: 0.629934\n",
      "[814]\ttraining's rmse: 0.0604081\tvalid_1's rmse: 0.62993\n",
      "[815]\ttraining's rmse: 0.0603335\tvalid_1's rmse: 0.629927\n",
      "[816]\ttraining's rmse: 0.060265\tvalid_1's rmse: 0.629933\n",
      "[817]\ttraining's rmse: 0.0601495\tvalid_1's rmse: 0.629923\n",
      "[818]\ttraining's rmse: 0.0600147\tvalid_1's rmse: 0.629906\n",
      "[819]\ttraining's rmse: 0.0599068\tvalid_1's rmse: 0.629886\n",
      "[820]\ttraining's rmse: 0.0597785\tvalid_1's rmse: 0.62986\n",
      "[821]\ttraining's rmse: 0.0597113\tvalid_1's rmse: 0.629859\n",
      "[822]\ttraining's rmse: 0.0596371\tvalid_1's rmse: 0.629848\n",
      "[823]\ttraining's rmse: 0.0595637\tvalid_1's rmse: 0.629848\n",
      "[824]\ttraining's rmse: 0.0594511\tvalid_1's rmse: 0.629838\n",
      "[825]\ttraining's rmse: 0.059382\tvalid_1's rmse: 0.629828\n",
      "[826]\ttraining's rmse: 0.0592923\tvalid_1's rmse: 0.629816\n",
      "[827]\ttraining's rmse: 0.0591941\tvalid_1's rmse: 0.62981\n",
      "[828]\ttraining's rmse: 0.059109\tvalid_1's rmse: 0.62981\n",
      "[829]\ttraining's rmse: 0.0590634\tvalid_1's rmse: 0.629805\n",
      "[830]\ttraining's rmse: 0.0589856\tvalid_1's rmse: 0.629803\n",
      "[831]\ttraining's rmse: 0.0588969\tvalid_1's rmse: 0.629802\n",
      "[832]\ttraining's rmse: 0.0588282\tvalid_1's rmse: 0.629792\n",
      "[833]\ttraining's rmse: 0.058749\tvalid_1's rmse: 0.629778\n",
      "[834]\ttraining's rmse: 0.0586578\tvalid_1's rmse: 0.629774\n",
      "[835]\ttraining's rmse: 0.0585898\tvalid_1's rmse: 0.62977\n",
      "[836]\ttraining's rmse: 0.0584602\tvalid_1's rmse: 0.62977\n",
      "[837]\ttraining's rmse: 0.0583459\tvalid_1's rmse: 0.629767\n",
      "[838]\ttraining's rmse: 0.0582359\tvalid_1's rmse: 0.629776\n",
      "[839]\ttraining's rmse: 0.0581218\tvalid_1's rmse: 0.629761\n",
      "[840]\ttraining's rmse: 0.0580022\tvalid_1's rmse: 0.629756\n",
      "[841]\ttraining's rmse: 0.0578806\tvalid_1's rmse: 0.629742\n",
      "[842]\ttraining's rmse: 0.0577941\tvalid_1's rmse: 0.629737\n",
      "[843]\ttraining's rmse: 0.0577273\tvalid_1's rmse: 0.629738\n",
      "[844]\ttraining's rmse: 0.0576072\tvalid_1's rmse: 0.629738\n",
      "[845]\ttraining's rmse: 0.0575099\tvalid_1's rmse: 0.629737\n",
      "[846]\ttraining's rmse: 0.0574638\tvalid_1's rmse: 0.629735\n",
      "[847]\ttraining's rmse: 0.0573974\tvalid_1's rmse: 0.629735\n",
      "[848]\ttraining's rmse: 0.0572936\tvalid_1's rmse: 0.629736\n",
      "[849]\ttraining's rmse: 0.0572069\tvalid_1's rmse: 0.629737\n",
      "[850]\ttraining's rmse: 0.0571118\tvalid_1's rmse: 0.629725\n",
      "[851]\ttraining's rmse: 0.0570227\tvalid_1's rmse: 0.629713\n",
      "[852]\ttraining's rmse: 0.0569531\tvalid_1's rmse: 0.629708\n",
      "[853]\ttraining's rmse: 0.0568516\tvalid_1's rmse: 0.629688\n",
      "[854]\ttraining's rmse: 0.0567524\tvalid_1's rmse: 0.629671\n",
      "[855]\ttraining's rmse: 0.056679\tvalid_1's rmse: 0.629672\n",
      "[856]\ttraining's rmse: 0.0565858\tvalid_1's rmse: 0.629662\n",
      "[857]\ttraining's rmse: 0.0564944\tvalid_1's rmse: 0.629669\n",
      "[858]\ttraining's rmse: 0.0564449\tvalid_1's rmse: 0.629664\n",
      "[859]\ttraining's rmse: 0.0563611\tvalid_1's rmse: 0.629661\n",
      "[860]\ttraining's rmse: 0.0562812\tvalid_1's rmse: 0.629644\n",
      "[861]\ttraining's rmse: 0.056185\tvalid_1's rmse: 0.629648\n",
      "[862]\ttraining's rmse: 0.0560803\tvalid_1's rmse: 0.629641\n",
      "[863]\ttraining's rmse: 0.0560102\tvalid_1's rmse: 0.629624\n",
      "[864]\ttraining's rmse: 0.0559035\tvalid_1's rmse: 0.629615\n",
      "[865]\ttraining's rmse: 0.0558371\tvalid_1's rmse: 0.629611\n",
      "[866]\ttraining's rmse: 0.0557926\tvalid_1's rmse: 0.629608\n",
      "[867]\ttraining's rmse: 0.0557128\tvalid_1's rmse: 0.629602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[868]\ttraining's rmse: 0.0556295\tvalid_1's rmse: 0.629586\n",
      "[869]\ttraining's rmse: 0.0555462\tvalid_1's rmse: 0.629599\n",
      "[870]\ttraining's rmse: 0.0554897\tvalid_1's rmse: 0.629593\n",
      "[871]\ttraining's rmse: 0.0554057\tvalid_1's rmse: 0.629601\n",
      "[872]\ttraining's rmse: 0.0553426\tvalid_1's rmse: 0.629591\n",
      "[873]\ttraining's rmse: 0.055258\tvalid_1's rmse: 0.629603\n",
      "[874]\ttraining's rmse: 0.0551826\tvalid_1's rmse: 0.629602\n",
      "[875]\ttraining's rmse: 0.0550864\tvalid_1's rmse: 0.629606\n",
      "[876]\ttraining's rmse: 0.055015\tvalid_1's rmse: 0.629595\n",
      "[877]\ttraining's rmse: 0.0549351\tvalid_1's rmse: 0.629582\n",
      "[878]\ttraining's rmse: 0.0548545\tvalid_1's rmse: 0.629587\n",
      "[879]\ttraining's rmse: 0.0547555\tvalid_1's rmse: 0.629588\n",
      "[880]\ttraining's rmse: 0.0547073\tvalid_1's rmse: 0.629581\n",
      "[881]\ttraining's rmse: 0.0546173\tvalid_1's rmse: 0.629563\n",
      "[882]\ttraining's rmse: 0.0545618\tvalid_1's rmse: 0.629566\n",
      "[883]\ttraining's rmse: 0.0545171\tvalid_1's rmse: 0.629565\n",
      "[884]\ttraining's rmse: 0.0544589\tvalid_1's rmse: 0.62956\n",
      "[885]\ttraining's rmse: 0.0543664\tvalid_1's rmse: 0.629547\n",
      "[886]\ttraining's rmse: 0.0542893\tvalid_1's rmse: 0.629548\n",
      "[887]\ttraining's rmse: 0.0542343\tvalid_1's rmse: 0.629546\n",
      "[888]\ttraining's rmse: 0.0541689\tvalid_1's rmse: 0.629546\n",
      "[889]\ttraining's rmse: 0.0540714\tvalid_1's rmse: 0.629543\n",
      "[890]\ttraining's rmse: 0.0540013\tvalid_1's rmse: 0.629538\n",
      "[891]\ttraining's rmse: 0.0539717\tvalid_1's rmse: 0.629533\n",
      "[892]\ttraining's rmse: 0.053883\tvalid_1's rmse: 0.629517\n",
      "[893]\ttraining's rmse: 0.0538327\tvalid_1's rmse: 0.629512\n",
      "[894]\ttraining's rmse: 0.0537769\tvalid_1's rmse: 0.629519\n",
      "[895]\ttraining's rmse: 0.0537239\tvalid_1's rmse: 0.629521\n",
      "[896]\ttraining's rmse: 0.0536251\tvalid_1's rmse: 0.629518\n",
      "[897]\ttraining's rmse: 0.0535703\tvalid_1's rmse: 0.629521\n",
      "[898]\ttraining's rmse: 0.0535021\tvalid_1's rmse: 0.62951\n",
      "[899]\ttraining's rmse: 0.0534109\tvalid_1's rmse: 0.629501\n",
      "[900]\ttraining's rmse: 0.0533346\tvalid_1's rmse: 0.629492\n",
      "[901]\ttraining's rmse: 0.0532506\tvalid_1's rmse: 0.629488\n",
      "[902]\ttraining's rmse: 0.0531808\tvalid_1's rmse: 0.629493\n",
      "[903]\ttraining's rmse: 0.053083\tvalid_1's rmse: 0.629489\n",
      "[904]\ttraining's rmse: 0.0530077\tvalid_1's rmse: 0.629488\n",
      "[905]\ttraining's rmse: 0.0529604\tvalid_1's rmse: 0.629477\n",
      "[906]\ttraining's rmse: 0.0528768\tvalid_1's rmse: 0.629472\n",
      "[907]\ttraining's rmse: 0.0528047\tvalid_1's rmse: 0.62946\n",
      "[908]\ttraining's rmse: 0.0527054\tvalid_1's rmse: 0.629454\n",
      "[909]\ttraining's rmse: 0.0526255\tvalid_1's rmse: 0.62944\n",
      "[910]\ttraining's rmse: 0.0525448\tvalid_1's rmse: 0.629432\n",
      "[911]\ttraining's rmse: 0.0524786\tvalid_1's rmse: 0.629429\n",
      "[912]\ttraining's rmse: 0.0523901\tvalid_1's rmse: 0.629409\n",
      "[913]\ttraining's rmse: 0.0522894\tvalid_1's rmse: 0.629403\n",
      "[914]\ttraining's rmse: 0.0522154\tvalid_1's rmse: 0.629404\n",
      "[915]\ttraining's rmse: 0.0521721\tvalid_1's rmse: 0.629402\n",
      "[916]\ttraining's rmse: 0.0521036\tvalid_1's rmse: 0.629402\n",
      "[917]\ttraining's rmse: 0.0520279\tvalid_1's rmse: 0.629394\n",
      "[918]\ttraining's rmse: 0.0519644\tvalid_1's rmse: 0.629399\n",
      "[919]\ttraining's rmse: 0.0518988\tvalid_1's rmse: 0.629382\n",
      "[920]\ttraining's rmse: 0.051843\tvalid_1's rmse: 0.629384\n",
      "[921]\ttraining's rmse: 0.0518003\tvalid_1's rmse: 0.62937\n",
      "[922]\ttraining's rmse: 0.0517175\tvalid_1's rmse: 0.62936\n",
      "[923]\ttraining's rmse: 0.0516565\tvalid_1's rmse: 0.629356\n",
      "[924]\ttraining's rmse: 0.0516152\tvalid_1's rmse: 0.629357\n",
      "[925]\ttraining's rmse: 0.051564\tvalid_1's rmse: 0.629357\n",
      "[926]\ttraining's rmse: 0.0514575\tvalid_1's rmse: 0.629333\n",
      "[927]\ttraining's rmse: 0.0514041\tvalid_1's rmse: 0.62933\n",
      "[928]\ttraining's rmse: 0.0513294\tvalid_1's rmse: 0.629313\n",
      "[929]\ttraining's rmse: 0.0512637\tvalid_1's rmse: 0.629309\n",
      "[930]\ttraining's rmse: 0.0512002\tvalid_1's rmse: 0.629309\n",
      "[931]\ttraining's rmse: 0.0511461\tvalid_1's rmse: 0.62931\n",
      "[932]\ttraining's rmse: 0.051066\tvalid_1's rmse: 0.629307\n",
      "[933]\ttraining's rmse: 0.0510305\tvalid_1's rmse: 0.629305\n",
      "[934]\ttraining's rmse: 0.0509742\tvalid_1's rmse: 0.629309\n",
      "[935]\ttraining's rmse: 0.050886\tvalid_1's rmse: 0.629307\n",
      "[936]\ttraining's rmse: 0.0508181\tvalid_1's rmse: 0.629308\n",
      "[937]\ttraining's rmse: 0.050754\tvalid_1's rmse: 0.629303\n",
      "[938]\ttraining's rmse: 0.050698\tvalid_1's rmse: 0.629305\n",
      "[939]\ttraining's rmse: 0.0506299\tvalid_1's rmse: 0.629301\n",
      "[940]\ttraining's rmse: 0.0506004\tvalid_1's rmse: 0.629299\n",
      "[941]\ttraining's rmse: 0.0505444\tvalid_1's rmse: 0.629302\n",
      "[942]\ttraining's rmse: 0.0504762\tvalid_1's rmse: 0.629293\n",
      "[943]\ttraining's rmse: 0.0504037\tvalid_1's rmse: 0.629282\n",
      "[944]\ttraining's rmse: 0.0503358\tvalid_1's rmse: 0.629277\n",
      "[945]\ttraining's rmse: 0.0502901\tvalid_1's rmse: 0.629274\n",
      "[946]\ttraining's rmse: 0.0501983\tvalid_1's rmse: 0.629275\n",
      "[947]\ttraining's rmse: 0.0501317\tvalid_1's rmse: 0.62927\n",
      "[948]\ttraining's rmse: 0.0500504\tvalid_1's rmse: 0.629264\n",
      "[949]\ttraining's rmse: 0.0499899\tvalid_1's rmse: 0.629269\n",
      "[950]\ttraining's rmse: 0.0499015\tvalid_1's rmse: 0.629275\n",
      "[951]\ttraining's rmse: 0.0498399\tvalid_1's rmse: 0.629268\n",
      "[952]\ttraining's rmse: 0.0498047\tvalid_1's rmse: 0.629269\n",
      "[953]\ttraining's rmse: 0.049761\tvalid_1's rmse: 0.629255\n",
      "[954]\ttraining's rmse: 0.0496738\tvalid_1's rmse: 0.629248\n",
      "[955]\ttraining's rmse: 0.0495934\tvalid_1's rmse: 0.629247\n",
      "[956]\ttraining's rmse: 0.0495353\tvalid_1's rmse: 0.629237\n",
      "[957]\ttraining's rmse: 0.0494514\tvalid_1's rmse: 0.629222\n",
      "[958]\ttraining's rmse: 0.0493618\tvalid_1's rmse: 0.629229\n",
      "[959]\ttraining's rmse: 0.0493119\tvalid_1's rmse: 0.629224\n",
      "[960]\ttraining's rmse: 0.0492297\tvalid_1's rmse: 0.629215\n",
      "[961]\ttraining's rmse: 0.0491751\tvalid_1's rmse: 0.62921\n",
      "[962]\ttraining's rmse: 0.0491329\tvalid_1's rmse: 0.629213\n",
      "[963]\ttraining's rmse: 0.04909\tvalid_1's rmse: 0.629211\n",
      "[964]\ttraining's rmse: 0.0490319\tvalid_1's rmse: 0.629206\n",
      "[965]\ttraining's rmse: 0.0489254\tvalid_1's rmse: 0.629199\n",
      "[966]\ttraining's rmse: 0.0488649\tvalid_1's rmse: 0.629212\n",
      "[967]\ttraining's rmse: 0.0487975\tvalid_1's rmse: 0.629199\n",
      "[968]\ttraining's rmse: 0.0487426\tvalid_1's rmse: 0.629188\n",
      "[969]\ttraining's rmse: 0.0486718\tvalid_1's rmse: 0.629182\n",
      "[970]\ttraining's rmse: 0.0486069\tvalid_1's rmse: 0.629174\n",
      "[971]\ttraining's rmse: 0.0485273\tvalid_1's rmse: 0.629157\n",
      "[972]\ttraining's rmse: 0.0484674\tvalid_1's rmse: 0.629158\n",
      "[973]\ttraining's rmse: 0.0483942\tvalid_1's rmse: 0.629151\n",
      "[974]\ttraining's rmse: 0.0483251\tvalid_1's rmse: 0.629158\n",
      "[975]\ttraining's rmse: 0.0482625\tvalid_1's rmse: 0.629154\n",
      "[976]\ttraining's rmse: 0.0482058\tvalid_1's rmse: 0.629156\n",
      "[977]\ttraining's rmse: 0.0481225\tvalid_1's rmse: 0.629145\n",
      "[978]\ttraining's rmse: 0.048058\tvalid_1's rmse: 0.629139\n",
      "[979]\ttraining's rmse: 0.0479839\tvalid_1's rmse: 0.629148\n",
      "[980]\ttraining's rmse: 0.0479223\tvalid_1's rmse: 0.629149\n",
      "[981]\ttraining's rmse: 0.0478866\tvalid_1's rmse: 0.629148\n",
      "[982]\ttraining's rmse: 0.0478263\tvalid_1's rmse: 0.629152\n",
      "[983]\ttraining's rmse: 0.0477594\tvalid_1's rmse: 0.629142\n",
      "[984]\ttraining's rmse: 0.0476983\tvalid_1's rmse: 0.629142\n",
      "[985]\ttraining's rmse: 0.0476253\tvalid_1's rmse: 0.629134\n",
      "[986]\ttraining's rmse: 0.0475534\tvalid_1's rmse: 0.629138\n",
      "[987]\ttraining's rmse: 0.047468\tvalid_1's rmse: 0.62913\n",
      "[988]\ttraining's rmse: 0.0473988\tvalid_1's rmse: 0.629125\n",
      "[989]\ttraining's rmse: 0.0473491\tvalid_1's rmse: 0.629125\n",
      "[990]\ttraining's rmse: 0.0472685\tvalid_1's rmse: 0.629118\n",
      "[991]\ttraining's rmse: 0.0471956\tvalid_1's rmse: 0.62911\n",
      "[992]\ttraining's rmse: 0.0471438\tvalid_1's rmse: 0.629101\n",
      "[993]\ttraining's rmse: 0.0470626\tvalid_1's rmse: 0.6291\n",
      "[994]\ttraining's rmse: 0.0469768\tvalid_1's rmse: 0.629089\n",
      "[995]\ttraining's rmse: 0.0469231\tvalid_1's rmse: 0.629089\n",
      "[996]\ttraining's rmse: 0.0468693\tvalid_1's rmse: 0.629091\n",
      "[997]\ttraining's rmse: 0.0468161\tvalid_1's rmse: 0.629083\n",
      "[998]\ttraining's rmse: 0.0467374\tvalid_1's rmse: 0.629081\n",
      "[999]\ttraining's rmse: 0.0467003\tvalid_1's rmse: 0.629084\n",
      "[1000]\ttraining's rmse: 0.0466572\tvalid_1's rmse: 0.629081\n",
      "[1001]\ttraining's rmse: 0.0466174\tvalid_1's rmse: 0.629078\n",
      "[1002]\ttraining's rmse: 0.0465555\tvalid_1's rmse: 0.629072\n",
      "[1003]\ttraining's rmse: 0.0464834\tvalid_1's rmse: 0.629057\n",
      "[1004]\ttraining's rmse: 0.0464413\tvalid_1's rmse: 0.629047\n",
      "[1005]\ttraining's rmse: 0.0464043\tvalid_1's rmse: 0.629041\n",
      "[1006]\ttraining's rmse: 0.0463642\tvalid_1's rmse: 0.629039\n",
      "[1007]\ttraining's rmse: 0.0463118\tvalid_1's rmse: 0.629032\n",
      "[1008]\ttraining's rmse: 0.0462404\tvalid_1's rmse: 0.62903\n",
      "[1009]\ttraining's rmse: 0.0462053\tvalid_1's rmse: 0.629029\n",
      "[1010]\ttraining's rmse: 0.0461461\tvalid_1's rmse: 0.629023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1011]\ttraining's rmse: 0.0460831\tvalid_1's rmse: 0.629019\n",
      "[1012]\ttraining's rmse: 0.0460232\tvalid_1's rmse: 0.629009\n",
      "[1013]\ttraining's rmse: 0.0459615\tvalid_1's rmse: 0.629008\n",
      "[1014]\ttraining's rmse: 0.0459297\tvalid_1's rmse: 0.629007\n",
      "[1015]\ttraining's rmse: 0.045884\tvalid_1's rmse: 0.629004\n",
      "[1016]\ttraining's rmse: 0.0458281\tvalid_1's rmse: 0.629007\n",
      "[1017]\ttraining's rmse: 0.0457693\tvalid_1's rmse: 0.629005\n",
      "[1018]\ttraining's rmse: 0.0457098\tvalid_1's rmse: 0.62901\n",
      "[1019]\ttraining's rmse: 0.0456239\tvalid_1's rmse: 0.628997\n",
      "[1020]\ttraining's rmse: 0.0455705\tvalid_1's rmse: 0.628998\n",
      "[1021]\ttraining's rmse: 0.0455302\tvalid_1's rmse: 0.628995\n",
      "[1022]\ttraining's rmse: 0.0454708\tvalid_1's rmse: 0.62899\n",
      "[1023]\ttraining's rmse: 0.0454176\tvalid_1's rmse: 0.628994\n",
      "[1024]\ttraining's rmse: 0.0453568\tvalid_1's rmse: 0.629005\n",
      "[1025]\ttraining's rmse: 0.0452872\tvalid_1's rmse: 0.629019\n",
      "[1026]\ttraining's rmse: 0.0452215\tvalid_1's rmse: 0.629008\n",
      "[1027]\ttraining's rmse: 0.0451593\tvalid_1's rmse: 0.629004\n",
      "[1028]\ttraining's rmse: 0.0451172\tvalid_1's rmse: 0.629\n",
      "[1029]\ttraining's rmse: 0.0450415\tvalid_1's rmse: 0.628998\n",
      "[1030]\ttraining's rmse: 0.0449936\tvalid_1's rmse: 0.628988\n",
      "[1031]\ttraining's rmse: 0.0449428\tvalid_1's rmse: 0.628978\n",
      "[1032]\ttraining's rmse: 0.0448646\tvalid_1's rmse: 0.628991\n",
      "[1033]\ttraining's rmse: 0.0448306\tvalid_1's rmse: 0.628991\n",
      "[1034]\ttraining's rmse: 0.0447588\tvalid_1's rmse: 0.628987\n",
      "[1035]\ttraining's rmse: 0.0446897\tvalid_1's rmse: 0.628989\n",
      "[1036]\ttraining's rmse: 0.0446409\tvalid_1's rmse: 0.62899\n",
      "[1037]\ttraining's rmse: 0.0445703\tvalid_1's rmse: 0.628982\n",
      "[1038]\ttraining's rmse: 0.0445152\tvalid_1's rmse: 0.628977\n",
      "[1039]\ttraining's rmse: 0.0444788\tvalid_1's rmse: 0.628976\n",
      "[1040]\ttraining's rmse: 0.0444123\tvalid_1's rmse: 0.628978\n",
      "[1041]\ttraining's rmse: 0.0443518\tvalid_1's rmse: 0.628965\n",
      "[1042]\ttraining's rmse: 0.0442931\tvalid_1's rmse: 0.628961\n",
      "[1043]\ttraining's rmse: 0.0442335\tvalid_1's rmse: 0.628949\n",
      "[1044]\ttraining's rmse: 0.0441919\tvalid_1's rmse: 0.628946\n",
      "[1045]\ttraining's rmse: 0.0441586\tvalid_1's rmse: 0.628947\n",
      "[1046]\ttraining's rmse: 0.0440995\tvalid_1's rmse: 0.628941\n",
      "[1047]\ttraining's rmse: 0.0440486\tvalid_1's rmse: 0.628934\n",
      "[1048]\ttraining's rmse: 0.0439979\tvalid_1's rmse: 0.628934\n",
      "[1049]\ttraining's rmse: 0.0439625\tvalid_1's rmse: 0.628932\n",
      "[1050]\ttraining's rmse: 0.0439002\tvalid_1's rmse: 0.628918\n",
      "[1051]\ttraining's rmse: 0.0438665\tvalid_1's rmse: 0.628916\n",
      "[1052]\ttraining's rmse: 0.0438281\tvalid_1's rmse: 0.628913\n",
      "[1053]\ttraining's rmse: 0.0437819\tvalid_1's rmse: 0.62891\n",
      "[1054]\ttraining's rmse: 0.0437243\tvalid_1's rmse: 0.628907\n",
      "[1055]\ttraining's rmse: 0.0436837\tvalid_1's rmse: 0.628912\n",
      "[1056]\ttraining's rmse: 0.0436314\tvalid_1's rmse: 0.628918\n",
      "[1057]\ttraining's rmse: 0.0435637\tvalid_1's rmse: 0.628918\n",
      "[1058]\ttraining's rmse: 0.0435082\tvalid_1's rmse: 0.628904\n",
      "[1059]\ttraining's rmse: 0.043463\tvalid_1's rmse: 0.628903\n",
      "[1060]\ttraining's rmse: 0.0433762\tvalid_1's rmse: 0.628898\n",
      "[1061]\ttraining's rmse: 0.043315\tvalid_1's rmse: 0.628897\n",
      "[1062]\ttraining's rmse: 0.0432534\tvalid_1's rmse: 0.6289\n",
      "[1063]\ttraining's rmse: 0.0431869\tvalid_1's rmse: 0.628898\n",
      "[1064]\ttraining's rmse: 0.0431083\tvalid_1's rmse: 0.628887\n",
      "[1065]\ttraining's rmse: 0.0430656\tvalid_1's rmse: 0.628888\n",
      "[1066]\ttraining's rmse: 0.0430263\tvalid_1's rmse: 0.628888\n",
      "[1067]\ttraining's rmse: 0.0429681\tvalid_1's rmse: 0.628887\n",
      "[1068]\ttraining's rmse: 0.0429318\tvalid_1's rmse: 0.628878\n",
      "[1069]\ttraining's rmse: 0.0428737\tvalid_1's rmse: 0.628874\n",
      "[1070]\ttraining's rmse: 0.0428271\tvalid_1's rmse: 0.628872\n",
      "[1071]\ttraining's rmse: 0.0427965\tvalid_1's rmse: 0.628864\n",
      "[1072]\ttraining's rmse: 0.0427406\tvalid_1's rmse: 0.628863\n",
      "[1073]\ttraining's rmse: 0.0427021\tvalid_1's rmse: 0.628864\n",
      "[1074]\ttraining's rmse: 0.0426629\tvalid_1's rmse: 0.628857\n",
      "[1075]\ttraining's rmse: 0.0426309\tvalid_1's rmse: 0.628855\n",
      "[1076]\ttraining's rmse: 0.0425512\tvalid_1's rmse: 0.628845\n",
      "[1077]\ttraining's rmse: 0.0424953\tvalid_1's rmse: 0.628855\n",
      "[1078]\ttraining's rmse: 0.0424309\tvalid_1's rmse: 0.628856\n",
      "[1079]\ttraining's rmse: 0.0423782\tvalid_1's rmse: 0.62885\n",
      "[1080]\ttraining's rmse: 0.0423122\tvalid_1's rmse: 0.628856\n",
      "[1081]\ttraining's rmse: 0.042282\tvalid_1's rmse: 0.628852\n",
      "[1082]\ttraining's rmse: 0.0422582\tvalid_1's rmse: 0.628854\n",
      "[1083]\ttraining's rmse: 0.0422009\tvalid_1's rmse: 0.628845\n",
      "[1084]\ttraining's rmse: 0.0421403\tvalid_1's rmse: 0.628832\n",
      "[1085]\ttraining's rmse: 0.0420822\tvalid_1's rmse: 0.628836\n",
      "[1086]\ttraining's rmse: 0.0420468\tvalid_1's rmse: 0.628828\n",
      "[1087]\ttraining's rmse: 0.0419738\tvalid_1's rmse: 0.628825\n",
      "[1088]\ttraining's rmse: 0.0419059\tvalid_1's rmse: 0.62882\n",
      "[1089]\ttraining's rmse: 0.0418423\tvalid_1's rmse: 0.628815\n",
      "[1090]\ttraining's rmse: 0.0417959\tvalid_1's rmse: 0.62882\n",
      "[1091]\ttraining's rmse: 0.0417651\tvalid_1's rmse: 0.628819\n",
      "[1092]\ttraining's rmse: 0.0417185\tvalid_1's rmse: 0.628824\n",
      "[1093]\ttraining's rmse: 0.0416882\tvalid_1's rmse: 0.628819\n",
      "[1094]\ttraining's rmse: 0.0416454\tvalid_1's rmse: 0.628817\n",
      "[1095]\ttraining's rmse: 0.0416003\tvalid_1's rmse: 0.628806\n",
      "[1096]\ttraining's rmse: 0.041554\tvalid_1's rmse: 0.628811\n",
      "[1097]\ttraining's rmse: 0.041523\tvalid_1's rmse: 0.628815\n",
      "[1098]\ttraining's rmse: 0.0414765\tvalid_1's rmse: 0.628812\n",
      "[1099]\ttraining's rmse: 0.0414139\tvalid_1's rmse: 0.628806\n",
      "[1100]\ttraining's rmse: 0.0413732\tvalid_1's rmse: 0.628801\n",
      "[1101]\ttraining's rmse: 0.0413283\tvalid_1's rmse: 0.6288\n",
      "[1102]\ttraining's rmse: 0.0412939\tvalid_1's rmse: 0.628799\n",
      "[1103]\ttraining's rmse: 0.0412495\tvalid_1's rmse: 0.628792\n",
      "[1104]\ttraining's rmse: 0.0412069\tvalid_1's rmse: 0.628789\n",
      "[1105]\ttraining's rmse: 0.0411554\tvalid_1's rmse: 0.628785\n",
      "[1106]\ttraining's rmse: 0.041103\tvalid_1's rmse: 0.628783\n",
      "[1107]\ttraining's rmse: 0.041056\tvalid_1's rmse: 0.628779\n",
      "[1108]\ttraining's rmse: 0.0409994\tvalid_1's rmse: 0.62877\n",
      "[1109]\ttraining's rmse: 0.0409392\tvalid_1's rmse: 0.628768\n",
      "[1110]\ttraining's rmse: 0.0408778\tvalid_1's rmse: 0.628768\n",
      "[1111]\ttraining's rmse: 0.0408275\tvalid_1's rmse: 0.628768\n",
      "[1112]\ttraining's rmse: 0.0407986\tvalid_1's rmse: 0.628767\n",
      "[1113]\ttraining's rmse: 0.0407615\tvalid_1's rmse: 0.628761\n",
      "[1114]\ttraining's rmse: 0.0407155\tvalid_1's rmse: 0.628754\n",
      "[1115]\ttraining's rmse: 0.0406482\tvalid_1's rmse: 0.628755\n",
      "[1116]\ttraining's rmse: 0.0405899\tvalid_1's rmse: 0.628747\n",
      "[1117]\ttraining's rmse: 0.0405453\tvalid_1's rmse: 0.628747\n",
      "[1118]\ttraining's rmse: 0.0405089\tvalid_1's rmse: 0.62875\n",
      "[1119]\ttraining's rmse: 0.0404721\tvalid_1's rmse: 0.628746\n",
      "[1120]\ttraining's rmse: 0.0404339\tvalid_1's rmse: 0.628748\n",
      "[1121]\ttraining's rmse: 0.0403851\tvalid_1's rmse: 0.628752\n",
      "[1122]\ttraining's rmse: 0.0403553\tvalid_1's rmse: 0.628745\n",
      "[1123]\ttraining's rmse: 0.0403104\tvalid_1's rmse: 0.628743\n",
      "[1124]\ttraining's rmse: 0.0402709\tvalid_1's rmse: 0.628738\n",
      "[1125]\ttraining's rmse: 0.0402355\tvalid_1's rmse: 0.628729\n",
      "[1126]\ttraining's rmse: 0.0401716\tvalid_1's rmse: 0.628731\n",
      "[1127]\ttraining's rmse: 0.0401278\tvalid_1's rmse: 0.628726\n",
      "[1128]\ttraining's rmse: 0.0400686\tvalid_1's rmse: 0.628724\n",
      "[1129]\ttraining's rmse: 0.0400462\tvalid_1's rmse: 0.628723\n",
      "[1130]\ttraining's rmse: 0.0400088\tvalid_1's rmse: 0.628722\n",
      "[1131]\ttraining's rmse: 0.0399554\tvalid_1's rmse: 0.62872\n",
      "[1132]\ttraining's rmse: 0.0398941\tvalid_1's rmse: 0.62872\n",
      "[1133]\ttraining's rmse: 0.0398458\tvalid_1's rmse: 0.628709\n",
      "[1134]\ttraining's rmse: 0.0398151\tvalid_1's rmse: 0.62871\n",
      "[1135]\ttraining's rmse: 0.0397627\tvalid_1's rmse: 0.628701\n",
      "[1136]\ttraining's rmse: 0.0397097\tvalid_1's rmse: 0.628698\n",
      "[1137]\ttraining's rmse: 0.0396713\tvalid_1's rmse: 0.628691\n",
      "[1138]\ttraining's rmse: 0.0396078\tvalid_1's rmse: 0.628697\n",
      "[1139]\ttraining's rmse: 0.0395558\tvalid_1's rmse: 0.628691\n",
      "[1140]\ttraining's rmse: 0.0395203\tvalid_1's rmse: 0.628694\n",
      "[1141]\ttraining's rmse: 0.0394972\tvalid_1's rmse: 0.628697\n",
      "[1142]\ttraining's rmse: 0.0394672\tvalid_1's rmse: 0.628699\n",
      "[1143]\ttraining's rmse: 0.0394202\tvalid_1's rmse: 0.628697\n",
      "[1144]\ttraining's rmse: 0.0393811\tvalid_1's rmse: 0.628692\n",
      "[1145]\ttraining's rmse: 0.0393488\tvalid_1's rmse: 0.62869\n",
      "[1146]\ttraining's rmse: 0.0393084\tvalid_1's rmse: 0.628686\n",
      "[1147]\ttraining's rmse: 0.0392584\tvalid_1's rmse: 0.628679\n",
      "[1148]\ttraining's rmse: 0.0392102\tvalid_1's rmse: 0.62868\n",
      "[1149]\ttraining's rmse: 0.0391607\tvalid_1's rmse: 0.628673\n",
      "[1150]\ttraining's rmse: 0.0391065\tvalid_1's rmse: 0.628673\n",
      "[1151]\ttraining's rmse: 0.0390713\tvalid_1's rmse: 0.62867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1152]\ttraining's rmse: 0.0390279\tvalid_1's rmse: 0.62867\n",
      "[1153]\ttraining's rmse: 0.0389908\tvalid_1's rmse: 0.628668\n",
      "[1154]\ttraining's rmse: 0.0389447\tvalid_1's rmse: 0.628673\n",
      "[1155]\ttraining's rmse: 0.0388917\tvalid_1's rmse: 0.628666\n",
      "[1156]\ttraining's rmse: 0.0388584\tvalid_1's rmse: 0.628666\n",
      "[1157]\ttraining's rmse: 0.0387998\tvalid_1's rmse: 0.628661\n",
      "[1158]\ttraining's rmse: 0.0387683\tvalid_1's rmse: 0.628661\n",
      "[1159]\ttraining's rmse: 0.0387455\tvalid_1's rmse: 0.62866\n",
      "[1160]\ttraining's rmse: 0.0386948\tvalid_1's rmse: 0.628661\n",
      "[1161]\ttraining's rmse: 0.0386484\tvalid_1's rmse: 0.628659\n",
      "[1162]\ttraining's rmse: 0.0386027\tvalid_1's rmse: 0.628658\n",
      "[1163]\ttraining's rmse: 0.0385724\tvalid_1's rmse: 0.628657\n",
      "[1164]\ttraining's rmse: 0.0385399\tvalid_1's rmse: 0.628657\n",
      "[1165]\ttraining's rmse: 0.0384826\tvalid_1's rmse: 0.628653\n",
      "[1166]\ttraining's rmse: 0.0384253\tvalid_1's rmse: 0.628648\n",
      "[1167]\ttraining's rmse: 0.0383781\tvalid_1's rmse: 0.62865\n",
      "[1168]\ttraining's rmse: 0.0383259\tvalid_1's rmse: 0.62866\n",
      "[1169]\ttraining's rmse: 0.0382722\tvalid_1's rmse: 0.628659\n",
      "[1170]\ttraining's rmse: 0.0382426\tvalid_1's rmse: 0.628662\n",
      "[1171]\ttraining's rmse: 0.0381878\tvalid_1's rmse: 0.628659\n",
      "[1172]\ttraining's rmse: 0.0381401\tvalid_1's rmse: 0.628663\n",
      "[1173]\ttraining's rmse: 0.0381129\tvalid_1's rmse: 0.628661\n",
      "[1174]\ttraining's rmse: 0.0380638\tvalid_1's rmse: 0.628656\n",
      "[1175]\ttraining's rmse: 0.0380356\tvalid_1's rmse: 0.628658\n",
      "[1176]\ttraining's rmse: 0.0379836\tvalid_1's rmse: 0.628657\n",
      "[1177]\ttraining's rmse: 0.0379481\tvalid_1's rmse: 0.628654\n",
      "[1178]\ttraining's rmse: 0.0378991\tvalid_1's rmse: 0.628657\n",
      "[1179]\ttraining's rmse: 0.0378408\tvalid_1's rmse: 0.628652\n",
      "[1180]\ttraining's rmse: 0.0378031\tvalid_1's rmse: 0.62865\n",
      "[1181]\ttraining's rmse: 0.0377467\tvalid_1's rmse: 0.628648\n",
      "[1182]\ttraining's rmse: 0.0376972\tvalid_1's rmse: 0.628643\n",
      "[1183]\ttraining's rmse: 0.0376548\tvalid_1's rmse: 0.628639\n",
      "[1184]\ttraining's rmse: 0.0376126\tvalid_1's rmse: 0.62864\n",
      "[1185]\ttraining's rmse: 0.0375659\tvalid_1's rmse: 0.628639\n",
      "[1186]\ttraining's rmse: 0.0375252\tvalid_1's rmse: 0.628636\n",
      "[1187]\ttraining's rmse: 0.0375003\tvalid_1's rmse: 0.628634\n",
      "[1188]\ttraining's rmse: 0.0374642\tvalid_1's rmse: 0.628633\n",
      "[1189]\ttraining's rmse: 0.0374423\tvalid_1's rmse: 0.628635\n",
      "[1190]\ttraining's rmse: 0.0373953\tvalid_1's rmse: 0.628633\n",
      "[1191]\ttraining's rmse: 0.0373326\tvalid_1's rmse: 0.628627\n",
      "[1192]\ttraining's rmse: 0.0373145\tvalid_1's rmse: 0.62863\n",
      "[1193]\ttraining's rmse: 0.0372734\tvalid_1's rmse: 0.628627\n",
      "[1194]\ttraining's rmse: 0.0372308\tvalid_1's rmse: 0.628624\n",
      "[1195]\ttraining's rmse: 0.0371992\tvalid_1's rmse: 0.62863\n",
      "[1196]\ttraining's rmse: 0.0371711\tvalid_1's rmse: 0.62863\n",
      "[1197]\ttraining's rmse: 0.0371286\tvalid_1's rmse: 0.628627\n",
      "[1198]\ttraining's rmse: 0.0370729\tvalid_1's rmse: 0.628629\n",
      "[1199]\ttraining's rmse: 0.0370313\tvalid_1's rmse: 0.628633\n",
      "[1200]\ttraining's rmse: 0.0369757\tvalid_1's rmse: 0.628626\n",
      "[1201]\ttraining's rmse: 0.0369235\tvalid_1's rmse: 0.62862\n",
      "[1202]\ttraining's rmse: 0.0368879\tvalid_1's rmse: 0.628622\n",
      "[1203]\ttraining's rmse: 0.0368576\tvalid_1's rmse: 0.628622\n",
      "[1204]\ttraining's rmse: 0.0367998\tvalid_1's rmse: 0.628616\n",
      "[1205]\ttraining's rmse: 0.0367634\tvalid_1's rmse: 0.628616\n",
      "[1206]\ttraining's rmse: 0.0367304\tvalid_1's rmse: 0.628614\n",
      "[1207]\ttraining's rmse: 0.0366944\tvalid_1's rmse: 0.628614\n",
      "[1208]\ttraining's rmse: 0.0366644\tvalid_1's rmse: 0.628615\n",
      "[1209]\ttraining's rmse: 0.0366194\tvalid_1's rmse: 0.62861\n",
      "[1210]\ttraining's rmse: 0.0365923\tvalid_1's rmse: 0.628609\n",
      "[1211]\ttraining's rmse: 0.0365456\tvalid_1's rmse: 0.628606\n",
      "[1212]\ttraining's rmse: 0.0365072\tvalid_1's rmse: 0.62861\n",
      "[1213]\ttraining's rmse: 0.0364531\tvalid_1's rmse: 0.628608\n",
      "[1214]\ttraining's rmse: 0.0364144\tvalid_1's rmse: 0.628607\n",
      "[1215]\ttraining's rmse: 0.0363898\tvalid_1's rmse: 0.628612\n",
      "[1216]\ttraining's rmse: 0.0363719\tvalid_1's rmse: 0.628611\n",
      "[1217]\ttraining's rmse: 0.0363307\tvalid_1's rmse: 0.628607\n",
      "[1218]\ttraining's rmse: 0.0363001\tvalid_1's rmse: 0.628603\n",
      "[1219]\ttraining's rmse: 0.0362587\tvalid_1's rmse: 0.628597\n",
      "[1220]\ttraining's rmse: 0.0362229\tvalid_1's rmse: 0.628588\n",
      "[1221]\ttraining's rmse: 0.0361797\tvalid_1's rmse: 0.628591\n",
      "[1222]\ttraining's rmse: 0.0361403\tvalid_1's rmse: 0.628586\n",
      "[1223]\ttraining's rmse: 0.0360881\tvalid_1's rmse: 0.628578\n",
      "[1224]\ttraining's rmse: 0.0360583\tvalid_1's rmse: 0.628578\n",
      "[1225]\ttraining's rmse: 0.0360147\tvalid_1's rmse: 0.628578\n",
      "[1226]\ttraining's rmse: 0.0359807\tvalid_1's rmse: 0.628572\n",
      "[1227]\ttraining's rmse: 0.0359573\tvalid_1's rmse: 0.628568\n",
      "[1228]\ttraining's rmse: 0.0359195\tvalid_1's rmse: 0.628568\n",
      "[1229]\ttraining's rmse: 0.0358745\tvalid_1's rmse: 0.628568\n",
      "[1230]\ttraining's rmse: 0.0358252\tvalid_1's rmse: 0.628566\n",
      "[1231]\ttraining's rmse: 0.0357933\tvalid_1's rmse: 0.628561\n",
      "[1232]\ttraining's rmse: 0.0357517\tvalid_1's rmse: 0.628559\n",
      "[1233]\ttraining's rmse: 0.0357028\tvalid_1's rmse: 0.628558\n",
      "[1234]\ttraining's rmse: 0.035659\tvalid_1's rmse: 0.628555\n",
      "[1235]\ttraining's rmse: 0.0356288\tvalid_1's rmse: 0.628557\n",
      "[1236]\ttraining's rmse: 0.0355902\tvalid_1's rmse: 0.628552\n",
      "[1237]\ttraining's rmse: 0.0355627\tvalid_1's rmse: 0.628553\n",
      "[1238]\ttraining's rmse: 0.0355276\tvalid_1's rmse: 0.628559\n",
      "[1239]\ttraining's rmse: 0.0354862\tvalid_1's rmse: 0.628551\n",
      "[1240]\ttraining's rmse: 0.0354401\tvalid_1's rmse: 0.628551\n",
      "[1241]\ttraining's rmse: 0.0353954\tvalid_1's rmse: 0.628548\n",
      "[1242]\ttraining's rmse: 0.0353547\tvalid_1's rmse: 0.628552\n",
      "[1243]\ttraining's rmse: 0.0353129\tvalid_1's rmse: 0.628555\n",
      "[1244]\ttraining's rmse: 0.0352899\tvalid_1's rmse: 0.628555\n",
      "[1245]\ttraining's rmse: 0.0352453\tvalid_1's rmse: 0.628556\n",
      "[1246]\ttraining's rmse: 0.0352087\tvalid_1's rmse: 0.62856\n",
      "[1247]\ttraining's rmse: 0.0351861\tvalid_1's rmse: 0.628559\n",
      "[1248]\ttraining's rmse: 0.0351592\tvalid_1's rmse: 0.628556\n",
      "[1249]\ttraining's rmse: 0.0351398\tvalid_1's rmse: 0.628553\n",
      "[1250]\ttraining's rmse: 0.0351196\tvalid_1's rmse: 0.628552\n",
      "[1251]\ttraining's rmse: 0.0350931\tvalid_1's rmse: 0.628551\n",
      "[1252]\ttraining's rmse: 0.035067\tvalid_1's rmse: 0.628551\n",
      "[1253]\ttraining's rmse: 0.0350166\tvalid_1's rmse: 0.628554\n",
      "[1254]\ttraining's rmse: 0.0349909\tvalid_1's rmse: 0.628556\n",
      "[1255]\ttraining's rmse: 0.034968\tvalid_1's rmse: 0.628553\n",
      "[1256]\ttraining's rmse: 0.0349281\tvalid_1's rmse: 0.628551\n",
      "[1257]\ttraining's rmse: 0.0348982\tvalid_1's rmse: 0.628551\n",
      "[1258]\ttraining's rmse: 0.0348691\tvalid_1's rmse: 0.628551\n",
      "[1259]\ttraining's rmse: 0.0348457\tvalid_1's rmse: 0.628551\n",
      "[1260]\ttraining's rmse: 0.0348205\tvalid_1's rmse: 0.628553\n",
      "[1261]\ttraining's rmse: 0.0347964\tvalid_1's rmse: 0.628551\n",
      "Early stopping, best iteration is:\n",
      "[1241]\ttraining's rmse: 0.0353954\tvalid_1's rmse: 0.628548\n"
     ]
    }
   ],
   "source": [
    "#Output\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_reduced, y_train3, test_size=0.1, random_state=1)\n",
    "lgb_train_data = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_val_data = lgb.Dataset(x_val, label=y_val)\n",
    "rmse_val = lgb.train(params, lgb_train_data, num_round, early_stopping_rounds=20, \n",
    "                         valid_sets=[lgb_train_data, lgb_val_data])\n",
    "y_pred_train = rmse_val.predict(x_train, num_iteration=rmse_val.best_iteration)\n",
    "y_pred_val = rmse_val.predict(x_val, num_iteration=rmse_val.best_iteration)\n",
    "rmse_v = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "rmse_t = np.sqrt(mean_squared_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submit = rmse_val.predict(x_test_reduced, num_iteration=rmse_val.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_id = pd.read_csv('test_grouped_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_id.loc[:, ~test_id.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'fullVisitorId':test_id['fullVisitorId'],'PredictedLogTotalRevenue_perCustomer':y_pred_submit})\n",
    "submission['fullVisitorId']= submission['fullVisitorId'].astype(str)\n",
    "submission['PredictedLogTotalRevenue_perCustomer']=submission['PredictedLogTotalRevenue_perCustomer'].apply(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296530,)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_LGBM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106969969400216"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028971592404011762"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6106975016256623"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02897159240402142"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110207603960199"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023738188273136025"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020294617196461973"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273708900068489"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607254141969766"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05903756234033532"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6581985771200763"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25507579206222797"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5168227779735912"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167359094023436"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671640628381363"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77272212017713"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7585244443135454"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8553213135732253"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5815554234060244"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532258686645664"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5987741886405407"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7531989950098282"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075212398674616"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9414817504736281"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_v1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
